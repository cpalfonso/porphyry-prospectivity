{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ca51ae",
   "metadata": {},
   "source": [
    "# Extract grid data\n",
    "\n",
    "This notebook will extract plate kinematic data from a plate model and other data from the `source_data` directory, writing the resulting dataset to a CSV file which can then be used to create the time-dependent prospectivity maps in the following notebooks (`02*.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db541f",
   "metadata": {},
   "source": [
    "## Notebook options\n",
    "\n",
    "These cells set some of the important variables and definitions used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abfc0d9",
   "metadata": {},
   "source": [
    "### Select plate model\n",
    "\n",
    "To use the plate model from the published paper (Alfonso et al., 2024), set `use_provided_plate_model` to `True`. Otherwise, leave `use_provided_plate_model` as `False` and set `plate_model_name` to a valid model name for the [`plate-model-manager`](https://github.com/michaelchin/plate-model-manager/blob/4f66423b53950bf42f5dac1228e61fd1e19fdf6e/models.json) package, or set `plate_model_name` to `None` and place GPlates files in a directory named `plate_model`.\n",
    "\n",
    "| `use_provided_plate_model` | `plate_model_name` | result |\n",
    "| - | - | - |\n",
    "| `True` | Any | Use Alfonso et al., 2024 model |\n",
    "| `False` | Model name string (e.g. `\"muller2022\"`) | Use specified plate model |\n",
    "| `False` | `None` | Use files in `plate_model` directory |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088fe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://repo.gplates.org/webdav/pmm/muller2022/Rotations.zip\n",
      "The local file(s) is/are still good. Will not download again at this moment.\n",
      "downloading https://repo.gplates.org/webdav/pmm/muller2022/Topologies.zip\n",
      "The local file(s) is/are still good. Will not download again at this moment.\n",
      "downloading https://repo.gplates.org/webdav/pmm/muller2022/StaticPolygons.zip\n",
      "The local file(s) is/are still good. Will not download again at this moment.\n"
     ]
    }
   ],
   "source": [
    "use_provided_plate_model = True\n",
    "plate_model_name = \"muller2022\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08942f57",
   "metadata": {},
   "source": [
    "### Set other parameters\n",
    "\n",
    "Perhaps the most important options here are `n_jobs` and `max_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolution of output grid (degrees)\n",
    "grid_resolution = 0.5\n",
    "\n",
    "# Number of processes to use\n",
    "n_jobs = 4\n",
    "\n",
    "# Overwrite any existing output files\n",
    "overwrite = False\n",
    "\n",
    "# Timespan for analysis\n",
    "min_time = 0\n",
    "max_time = 170\n",
    "\n",
    "# Control verbosity level of logging output\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa8521",
   "metadata": {},
   "source": [
    "If any of the following exist as environment variables, they will replace the values defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Override above values with environment variables, if they exist\n",
    "grid_resolution = float(os.environ.get(\"GRID_RESOLUTION\", grid_resolution))\n",
    "n_jobs = int(os.environ.get(\"N_JOBS\", n_jobs))\n",
    "overwrite = bool(int(os.environ.get(\"OVERWRITE\", overwrite)))\n",
    "min_time = int(os.environ.get(\"MIN_TIME\", min_time))\n",
    "max_time = int(os.environ.get(\"MAX_TIME\", max_time))\n",
    "verbose = bool(int(os.environ.get(\"VERBOSE\", verbose)))\n",
    "\n",
    "times = range(min_time, max_time + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639c87e",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "\n",
    "Imports, definitions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f00fa",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7064cd0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T03:48:21.441820Z",
     "iopub.status.busy": "2024-02-02T03:48:21.441667Z",
     "iopub.status.idle": "2024-02-02T03:48:23.212572Z",
     "shell.execute_reply": "2024-02-02T03:48:23.211829Z"
    },
    "papermill": {
     "duration": 1.778325,
     "end_time": "2024-02-02T03:48:23.214220",
     "exception": false,
     "start_time": "2024-02-02T03:48:21.435895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONWARNINGS=ignore::UserWarning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from gplately.tools import plate_isotherm_depth\n",
    "\n",
    "from lib.assign_regions import assign_regions\n",
    "from lib.calculate_convergence import run_calculate_convergence\n",
    "from lib.check_files import (\n",
    "    check_plate_model,\n",
    "    check_source_data,\n",
    ")\n",
    "from lib.coregister_combined_point_data import run_coregister_combined_point_data\n",
    "from lib.coregister_crustal_thickness import run_coregister_crustal_thickness\n",
    "from lib.coregister_ocean_rasters import run_coregister_ocean_rasters\n",
    "from lib.create_study_area_polygons import run_create_study_area_polygons\n",
    "from lib.erodep import calculate_erodep\n",
    "from lib.misc import calculate_slab_flux\n",
    "from lib.plate_models import get_plate_reconstruction\n",
    "from lib.pu import generate_grid_points\n",
    "from lib.slab_dip import calculate_slab_dip\n",
    "from lib.water import calculate_water_thickness\n",
    "\n",
    "# Suppress occasional joblib warnings\n",
    "%env PYTHONWARNINGS=ignore::UserWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f11f60",
   "metadata": {},
   "source": [
    "### Input and output files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7c26b",
   "metadata": {},
   "source": [
    "If necessary, the plate model will be downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_model_dir = \"plate_model\"\n",
    "if use_provided_plate_model:\n",
    "    check_plate_model(plate_model_dir, verbose=True)\n",
    "    plate_model_name = None\n",
    "plate_model = get_plate_reconstruction(\n",
    "    model_name=plate_model_name,\n",
    "    model_dir=plate_model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8d396",
   "metadata": {},
   "source": [
    "The directory containing the datasets to be extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee894246",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"source_data\"\n",
    "data_dir = check_source_data(data_dir, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a851a25",
   "metadata": {},
   "source": [
    "Output files will be created in this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba69c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"extracted_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51a6e4",
   "metadata": {},
   "source": [
    "The following input directories are all relative to `data_dir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb666f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file with known deposits; columns:\n",
    "# lon, lat, age (Ma)\n",
    "deposits_filename = \"deposit_data_global.csv\"\n",
    "\n",
    "# If desired, categorise deposits according to location\n",
    "# Should be a shapefile or GeoJSON containing polygons\n",
    "# with a 'region' attribute\n",
    "regions_filename = \"regions.geojson\"\n",
    "\n",
    "# Seafloor age grid directory\n",
    "# Filename format 'seafloor_age_{time}Ma.nc'\n",
    "agegrid_dir = \"AgeGrids\"\n",
    "\n",
    "# Seafloor sediment thickness directory\n",
    "# Filename format 'sediment_thickness_{time}Ma.nc'\n",
    "sedthick_dir = \"SedimentThickness\"\n",
    "\n",
    "# Seafloor carbonate sediment thickness directory\n",
    "# Filename format 'carbonate_thickness_{time}Ma.nc'\n",
    "carbonate_dir = \"CarbonateThickness\"\n",
    "\n",
    "# Oceanic crustal CO2 density directory\n",
    "# Filename format 'crustal_co2_{time}Ma.nc'\n",
    "co2_dir = \"CrustalCO2\"\n",
    "\n",
    "# Overriding plate thickness directory\n",
    "# Filename format 'crustal_thickness_{time}Ma.nc'\n",
    "crustal_thickness_dir = \"CrustalThickness\"\n",
    "\n",
    "# Cumulative subducted sediments/carbonates/etc. directory\n",
    "# Filename format 'sediment_thickness/cumulative_density_{time}Ma.nc',\n",
    "# 'carbonate_thickness/cumulative_density_{time}Ma.nc', etc.\n",
    "subducted_quantities_dir = \"SubductedQuantities\"\n",
    "\n",
    "# Erosion/deposition rate directory\n",
    "# Filename format 'erosion_deposition_{time}Ma.nc'\n",
    "erodep_dir = \"ErosionDeposition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d44ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle relative file/directory paths\n",
    "\n",
    "deposits_filename = os.path.join(data_dir, deposits_filename)\n",
    "regions_filename = os.path.join(data_dir, regions_filename)\n",
    "agegrid_dir = os.path.join(data_dir, agegrid_dir)\n",
    "sedthick_dir = os.path.join(data_dir, sedthick_dir)\n",
    "carbonate_dir = os.path.join(data_dir, carbonate_dir)\n",
    "co2_dir = os.path.join(data_dir, co2_dir)\n",
    "crustal_thickness_dir = os.path.join(data_dir, crustal_thickness_dir)\n",
    "subducted_quantities_dir = os.path.join(data_dir, subducted_quantities_dir)\n",
    "erodep_dir = os.path.join(data_dir, erodep_dir)\n",
    "\n",
    "subduction_data_filename = os.path.join(output_dir, \"subducting_plate_data.csv\")\n",
    "study_area_dir = os.path.join(output_dir, \"study_area_polygons\")\n",
    "output_filename = os.path.join(output_dir, \"grid_data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb746f63",
   "metadata": {
    "papermill": {
     "duration": 0.002464,
     "end_time": "2024-02-02T03:48:23.248325",
     "exception": false,
     "start_time": "2024-02-02T03:48:23.245861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate grid points\n",
    "\n",
    "The following function generates the grid of points at `grid_resolution`-degree resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7415048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T03:48:23.253919Z",
     "iopub.status.busy": "2024-02-02T03:48:23.253762Z",
     "iopub.status.idle": "2024-02-02T04:00:46.334243Z",
     "shell.execute_reply": "2024-02-02T04:00:46.333504Z"
    },
    "papermill": {
     "duration": 743.085753,
     "end_time": "2024-02-02T04:00:46.336486",
     "exception": false,
     "start_time": "2024-02-02T03:48:23.250733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n"
     ]
    }
   ],
   "source": [
    "if overwrite or not os.path.isdir(study_area_dir):\n",
    "    run_create_study_area_polygons(\n",
    "        nprocs=n_jobs,\n",
    "        times=times,\n",
    "        plate_reconstruction=plate_model,\n",
    "        output_dir=study_area_dir,\n",
    "        verbose=verbose,\n",
    "        return_output=False,\n",
    "    )\n",
    "grid_data = generate_grid_points(\n",
    "    times=times,\n",
    "    resolution=grid_resolution,\n",
    "    polygons_dir=study_area_dir,\n",
    "    plate_reconstruction=plate_model,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")\n",
    "grid_data = grid_data.dropna(subset=[\"present_lon\", \"present_lat\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e2ba866",
   "metadata": {
    "papermill": {
     "duration": 0.003992,
     "end_time": "2024-02-02T04:00:46.359243",
     "exception": false,
     "start_time": "2024-02-02T04:00:46.355251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Subducting plate data\n",
    "\n",
    "This cell will extract the subduction kinematics data from the plate model, along with datasets relating to the subducting oceanic plate: seafloor age, sediment and carbonate thickness, etc.\n",
    "However, if this data has already been extracted by another notebook and `overwrite` has not been set to `True`, then the data will be read from that file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c03c5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T04:00:46.368101Z",
     "iopub.status.busy": "2024-02-02T04:00:46.367950Z",
     "iopub.status.idle": "2024-02-02T04:01:19.620305Z",
     "shell.execute_reply": "2024-02-02T04:01:19.619676Z"
    },
    "papermill": {
     "duration": 33.258942,
     "end_time": "2024-02-02T04:01:19.622325",
     "exception": false,
     "start_time": "2024-02-02T04:00:46.363383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    subduction_data_filename is not None and os.path.isfile(subduction_data_filename)\n",
    ") and (not overwrite):\n",
    "    subduction_data = pd.read_csv(subduction_data_filename)\n",
    "else:\n",
    "    subduction_data = run_calculate_convergence(\n",
    "        nprocs=n_jobs,\n",
    "        min_time=min(times),\n",
    "        max_time=max(times),\n",
    "        plate_reconstruction=plate_model,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    subduction_data = run_coregister_ocean_rasters(\n",
    "        nprocs=n_jobs,\n",
    "        times=times,\n",
    "        input_data=subduction_data,\n",
    "        agegrid_dir=agegrid_dir,\n",
    "        plate_reconstruction=plate_model,\n",
    "        sedthick_dir=sedthick_dir,\n",
    "        carbonate_dir=carbonate_dir,\n",
    "        co2_dir=co2_dir,\n",
    "        subducted_thickness_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"plate_thickness\",\n",
    "        ),\n",
    "        subducted_sediments_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"sediment_thickness\",\n",
    "        ),\n",
    "        subducted_carbonates_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"carbonate_thickness\",\n",
    "        ),\n",
    "        subducted_water_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"water_thickness\",\n",
    "        ),\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    subduction_data[\"plate_thickness (m)\"] = plate_isotherm_depth(\n",
    "        subduction_data[\"seafloor_age (Ma)\"],\n",
    "        maxiter=100,\n",
    "    )\n",
    "    subduction_data = calculate_water_thickness(data=subduction_data)\n",
    "    subduction_data = calculate_slab_flux(subduction_data)\n",
    "    subduction_data = calculate_slab_dip(subduction_data)\n",
    "\n",
    "    if subduction_data_filename is not None:\n",
    "        subduction_data.to_csv(subduction_data_filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cafffa14",
   "metadata": {
    "papermill": {
     "duration": 0.004087,
     "end_time": "2024-02-02T04:01:19.631033",
     "exception": false,
     "start_time": "2024-02-02T04:01:19.626946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign subduction data to grid\n",
    "\n",
    "Here we assign the appropriate values for the subduction-related parameters (kinematics, seafloor age, etc.) to the grid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbadac30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T04:01:19.640034Z",
     "iopub.status.busy": "2024-02-02T04:01:19.639878Z",
     "iopub.status.idle": "2024-02-02T04:05:05.738324Z",
     "shell.execute_reply": "2024-02-02T04:05:05.737368Z"
    },
    "papermill": {
     "duration": 226.105267,
     "end_time": "2024-02-02T04:05:05.740282",
     "exception": false,
     "start_time": "2024-02-02T04:01:19.635015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = run_coregister_combined_point_data(\n",
    "    point_data=grid_data,\n",
    "    subduction_data=subduction_data,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c7067fe",
   "metadata": {
    "papermill": {
     "duration": 0.00402,
     "end_time": "2024-02-02T04:05:05.749000",
     "exception": false,
     "start_time": "2024-02-02T04:05:05.744980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign crustal thickness data to grid\n",
    "\n",
    "This cell extracts the overriding plate thickness at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317048a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T04:05:05.758504Z",
     "iopub.status.busy": "2024-02-02T04:05:05.758290Z",
     "iopub.status.idle": "2024-02-02T04:16:36.233874Z",
     "shell.execute_reply": "2024-02-02T04:16:36.233089Z"
    },
    "papermill": {
     "duration": 690.482762,
     "end_time": "2024-02-02T04:16:36.235792",
     "exception": false,
     "start_time": "2024-02-02T04:05:05.753030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = run_coregister_crustal_thickness(\n",
    "    point_data=coregistered_data,\n",
    "    input_dir=crustal_thickness_dir,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067ae47",
   "metadata": {
    "papermill": {
     "duration": 0.004439,
     "end_time": "2024-02-02T04:16:36.245512",
     "exception": false,
     "start_time": "2024-02-02T04:16:36.241073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculate cumulative erosion\n",
    "\n",
    "Here we calculate the cumulative erosion experienced by each point in the grid since its assigned age time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90d7da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T04:16:36.300115Z",
     "iopub.status.busy": "2024-02-02T04:16:36.299959Z",
     "iopub.status.idle": "2024-02-02T04:30:14.655649Z",
     "shell.execute_reply": "2024-02-02T04:30:14.654864Z"
    },
    "papermill": {
     "duration": 818.363315,
     "end_time": "2024-02-02T04:30:14.657562",
     "exception": false,
     "start_time": "2024-02-02T04:16:36.294247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = calculate_erodep(\n",
    "    coregistered_data,\n",
    "    input_dir=erodep_dir,\n",
    "    n_jobs=n_jobs,\n",
    "    column_name=\"erosion (m)\",\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a228c9cc",
   "metadata": {},
   "source": [
    "### Assign data to regions\n",
    "\n",
    "To divide the data into individual regions for the later analysis, we use the `regions_filename` defined earlier, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d520a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regions_filename is not None and os.path.isfile(regions_filename):\n",
    "    points = gpd.GeoSeries.from_xy(\n",
    "        coregistered_data[\"present_lon\"],\n",
    "        coregistered_data[\"present_lat\"],\n",
    "        index=coregistered_data.index,\n",
    "    )\n",
    "    coregistered_data[\"region\"] = assign_regions(\n",
    "        points,\n",
    "        regions=regions_filename,\n",
    "    )\n",
    "    del points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e28940",
   "metadata": {
    "papermill": {
     "duration": 0.00434,
     "end_time": "2024-02-02T04:30:14.666990",
     "exception": false,
     "start_time": "2024-02-02T04:30:14.662650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save to file\n",
    "\n",
    "Finally, we write the dataset to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "333c91a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T04:30:14.676124Z",
     "iopub.status.busy": "2024-02-02T04:30:14.675963Z",
     "iopub.status.idle": "2024-02-02T04:32:52.445583Z",
     "shell.execute_reply": "2024-02-02T04:32:52.444706Z"
    },
    "papermill": {
     "duration": 157.776457,
     "end_time": "2024-02-02T04:32:52.447511",
     "exception": false,
     "start_time": "2024-02-02T04:30:14.671054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b394a",
   "metadata": {
    "papermill": {
     "duration": 0.004145,
     "end_time": "2024-02-02T04:32:52.456519",
     "exception": false,
     "start_time": "2024-02-02T04:32:52.452374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2675.221756,
   "end_time": "2024-02-02T04:32:55.784266",
   "environment_variables": {},
   "exception": null,
   "input_path": "00b-extract_grid_data.ipynb",
   "output_path": "00b-extract_grid_data.ipynb",
   "parameters": {},
   "start_time": "2024-02-02T03:48:20.562510",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
