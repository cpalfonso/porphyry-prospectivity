{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e474db9",
   "metadata": {
    "papermill": {
     "duration": 0.005938,
     "end_time": "2024-07-30T08:34:51.598175",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.592237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract training data\n",
    "\n",
    "This notebook will extract plate kinematic data from a plate model and other data from the `source_data` directory, writing the resulting dataset to a CSV file which can then be used to train the models in the following notebooks (`01*.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbeab9",
   "metadata": {
    "papermill": {
     "duration": 0.004527,
     "end_time": "2024-07-30T08:34:51.607659",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.603132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook options\n",
    "\n",
    "These cells set some of the important variables and definitions used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab57c3d5",
   "metadata": {
    "papermill": {
     "duration": 0.004584,
     "end_time": "2024-07-30T08:34:51.616772",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.612188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Select plate model\n",
    "\n",
    "To use the plate model from the published paper (Alfonso et al., 2024), set `use_provided_plate_model` to `True`. Otherwise, leave `use_provided_plate_model` as `False` and set `plate_model_name` to a valid model name for the [`plate-model-manager`](https://github.com/michaelchin/plate-model-manager/blob/4f66423b53950bf42f5dac1228e61fd1e19fdf6e/models.json) package, or set `plate_model_name` to `None` and place GPlates files in a directory named `plate_model`.\n",
    "\n",
    "| `use_provided_plate_model` | `plate_model_name` | result |\n",
    "| - | - | - |\n",
    "| `True` | Any | Use Alfonso et al., 2024 model |\n",
    "| `False` | Model name string (e.g. `\"muller2022\"`) | Use specified plate model |\n",
    "| `False` | `None` | Use files in `plate_model` directory |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7b1534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:34:51.626563Z",
     "iopub.status.busy": "2024-07-30T08:34:51.626210Z",
     "iopub.status.idle": "2024-07-30T08:34:51.632608Z",
     "shell.execute_reply": "2024-07-30T08:34:51.632128Z"
    },
    "papermill": {
     "duration": 0.013694,
     "end_time": "2024-07-30T08:34:51.634606",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.620912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_provided_plate_model = True\n",
    "plate_model_name = \"muller2022\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1896136",
   "metadata": {
    "papermill": {
     "duration": 0.003627,
     "end_time": "2024-07-30T08:34:51.642404",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.638777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Set other parameters\n",
    "\n",
    "Perhaps the most important options here are `n_jobs` and `max_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0885a686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:34:51.651522Z",
     "iopub.status.busy": "2024-07-30T08:34:51.651207Z",
     "iopub.status.idle": "2024-07-30T08:34:51.655587Z",
     "shell.execute_reply": "2024-07-30T08:34:51.654875Z"
    },
    "papermill": {
     "duration": 0.011725,
     "end_time": "2024-07-30T08:34:51.657758",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.646033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Allow reproducibility of randomised results\n",
    "random_seed = 1234\n",
    "\n",
    "# Number of processes to use\n",
    "n_jobs = 4\n",
    "\n",
    "# Overwrite any existing output files\n",
    "overwrite = False\n",
    "\n",
    "# Timespan for analysis\n",
    "min_time = 0\n",
    "max_time = 170\n",
    "\n",
    "# Control verbosity level of logging output\n",
    "verbose = False\n",
    "\n",
    "# Number of unlabelled points to generate\n",
    "num_unlabelled = 200  # per timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee294e4e",
   "metadata": {
    "papermill": {
     "duration": 0.004136,
     "end_time": "2024-07-30T08:34:51.666625",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.662489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If any of the following exist as environment variables, they will replace the values defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67868847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:34:51.675656Z",
     "iopub.status.busy": "2024-07-30T08:34:51.675409Z",
     "iopub.status.idle": "2024-07-30T08:34:51.680144Z",
     "shell.execute_reply": "2024-07-30T08:34:51.679564Z"
    },
    "papermill": {
     "duration": 0.012456,
     "end_time": "2024-07-30T08:34:51.682892",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.670436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Override above values with environment variables, if they exist\n",
    "n_jobs = int(os.environ.get(\"N_JOBS\", n_jobs))\n",
    "overwrite = bool(int(os.environ.get(\"OVERWRITE\", overwrite)))\n",
    "min_time = int(os.environ.get(\"MIN_TIME\", min_time))\n",
    "max_time = int(os.environ.get(\"MAX_TIME\", max_time))\n",
    "verbose = bool(int(os.environ.get(\"VERBOSE\", verbose)))\n",
    "num_unlabelled = int(os.environ.get(\"NUM_UNLABELLED\", num_unlabelled))\n",
    "\n",
    "times = range(min_time, max_time + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa8fc32",
   "metadata": {
    "papermill": {
     "duration": 0.004828,
     "end_time": "2024-07-30T08:34:51.694078",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.689250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook setup\n",
    "\n",
    "Imports, definitions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1302b",
   "metadata": {
    "papermill": {
     "duration": 0.004136,
     "end_time": "2024-07-30T08:34:51.702774",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.698638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92a09be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:34:51.714341Z",
     "iopub.status.busy": "2024-07-30T08:34:51.713909Z",
     "iopub.status.idle": "2024-07-30T08:34:55.606534Z",
     "shell.execute_reply": "2024-07-30T08:34:55.606014Z"
    },
    "papermill": {
     "duration": 3.899998,
     "end_time": "2024-07-30T08:34:55.608229",
     "exception": false,
     "start_time": "2024-07-30T08:34:51.708231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONWARNINGS=ignore::UserWarning\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from gplately.tools import plate_isotherm_depth\n",
    "\n",
    "from lib.assign_regions import assign_regions\n",
    "from lib.calculate_convergence import run_calculate_convergence\n",
    "from lib.check_files import (\n",
    "    check_source_data,\n",
    "    check_plate_model,\n",
    ")\n",
    "from lib.combine_point_data import combine_point_data\n",
    "from lib.coregister_combined_point_data import run_coregister_combined_point_data\n",
    "from lib.coregister_crustal_thickness import run_coregister_crustal_thickness\n",
    "from lib.coregister_ocean_rasters import (\n",
    "    extract_subducted_thickness,\n",
    "    run_coregister_ocean_rasters,\n",
    ")\n",
    "from lib.create_study_area_polygons import run_create_study_area_polygons\n",
    "from lib.erodep import calculate_erodep\n",
    "from lib.generate_unlabelled_points import generate_unlabelled_points\n",
    "from lib.misc import calculate_slab_flux, calculate_carbon\n",
    "from lib.plate_models import get_plate_reconstruction\n",
    "from lib.slab_dip import calculate_slab_dip\n",
    "from lib.water import calculate_water_thickness\n",
    "\n",
    "# Suppress occasional joblib warnings\n",
    "%env PYTHONWARNINGS=ignore::UserWarning\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "880580d1",
   "metadata": {
    "papermill": {
     "duration": 0.004703,
     "end_time": "2024-07-30T08:34:55.617946",
     "exception": false,
     "start_time": "2024-07-30T08:34:55.613243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Input and output files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e17a79",
   "metadata": {
    "papermill": {
     "duration": 0.005503,
     "end_time": "2024-07-30T08:34:55.628106",
     "exception": false,
     "start_time": "2024-07-30T08:34:55.622603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If necessary, the plate model will be downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60656f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:34:55.638437Z",
     "iopub.status.busy": "2024-07-30T08:34:55.638181Z",
     "iopub.status.idle": "2024-07-30T08:35:41.897628Z",
     "shell.execute_reply": "2024-07-30T08:35:41.897011Z"
    },
    "papermill": {
     "duration": 46.266429,
     "end_time": "2024-07-30T08:35:41.899151",
     "exception": false,
     "start_time": "2024-07-30T08:34:55.632722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_model_dir = \"plate_model\"\n",
    "if use_provided_plate_model:\n",
    "    check_plate_model(plate_model_dir, verbose=True)\n",
    "    plate_model_name = None\n",
    "plate_model = get_plate_reconstruction(\n",
    "    model_name=plate_model_name,\n",
    "    model_dir=plate_model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6b313",
   "metadata": {
    "papermill": {
     "duration": 0.003834,
     "end_time": "2024-07-30T08:35:41.907148",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.903314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The directory containing the datasets to be extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb00231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:35:41.916066Z",
     "iopub.status.busy": "2024-07-30T08:35:41.915819Z",
     "iopub.status.idle": "2024-07-30T08:35:41.919791Z",
     "shell.execute_reply": "2024-07-30T08:35:41.919365Z"
    },
    "papermill": {
     "duration": 0.010668,
     "end_time": "2024-07-30T08:35:41.921443",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.910775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"source_data\"\n",
    "data_dir = check_source_data(data_dir, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbcd39d",
   "metadata": {
    "papermill": {
     "duration": 0.003775,
     "end_time": "2024-07-30T08:35:41.928993",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.925218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Output files will be created in this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cdb93cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:35:41.937481Z",
     "iopub.status.busy": "2024-07-30T08:35:41.937255Z",
     "iopub.status.idle": "2024-07-30T08:35:41.940774Z",
     "shell.execute_reply": "2024-07-30T08:35:41.940357Z"
    },
    "papermill": {
     "duration": 0.009777,
     "end_time": "2024-07-30T08:35:41.942310",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.932533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"extracted_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489edaa8",
   "metadata": {
    "papermill": {
     "duration": 0.004225,
     "end_time": "2024-07-30T08:35:41.950553",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.946328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following input directories are all relative to `data_dir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d7de4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:35:41.959538Z",
     "iopub.status.busy": "2024-07-30T08:35:41.959181Z",
     "iopub.status.idle": "2024-07-30T08:35:41.963241Z",
     "shell.execute_reply": "2024-07-30T08:35:41.962698Z"
    },
    "papermill": {
     "duration": 0.010289,
     "end_time": "2024-07-30T08:35:41.964695",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.954406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CSV file with known deposits; columns:\n",
    "# lon, lat, age (Ma)\n",
    "deposits_filename = \"deposit_data_global.csv\"\n",
    "\n",
    "# If desired, categorise deposits according to location\n",
    "# Should be a shapefile or GeoJSON containing polygons\n",
    "# with a 'region' attribute\n",
    "regions_filename = \"regions.geojson\"\n",
    "\n",
    "# Seafloor age grid directory\n",
    "# Filename format 'seafloor_age_{time}Ma.nc'\n",
    "agegrid_dir = \"AgeGrids\"\n",
    "\n",
    "# Seafloor sediment thickness directory\n",
    "# Filename format 'sediment_thickness_{time}Ma.nc'\n",
    "sedthick_dir = \"SedimentThickness\"\n",
    "\n",
    "# Seafloor carbonate sediment thickness directory\n",
    "# Filename format 'carbonate_thickness_{time}Ma.nc'\n",
    "carbonate_dir = \"CarbonateThickness\"\n",
    "\n",
    "# Oceanic crustal CO2 density directory\n",
    "# Filename format 'crustal_co2_{time}Ma.nc'\n",
    "co2_dir = \"CrustalCO2\"\n",
    "\n",
    "# Overriding plate thickness directory\n",
    "# Filename format 'crustal_thickness_{time}Ma.nc'\n",
    "crustal_thickness_dir = \"CrustalThickness\"\n",
    "\n",
    "# Cumulative subducted sediments/carbonates/etc. directory\n",
    "# Filename format 'sediment_thickness/cumulative_density_{time}Ma.nc',\n",
    "# 'carbonate_thickness/cumulative_density_{time}Ma.nc', etc.\n",
    "subducted_quantities_dir = \"SubductedQuantities\"\n",
    "\n",
    "# Erosion/deposition rate directory\n",
    "# Filename format 'erosion_deposition_{time}Ma.nc'\n",
    "erodep_dir = \"ErosionDeposition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32544941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:35:41.974213Z",
     "iopub.status.busy": "2024-07-30T08:35:41.974014Z",
     "iopub.status.idle": "2024-07-30T08:35:41.978087Z",
     "shell.execute_reply": "2024-07-30T08:35:41.977663Z"
    },
    "papermill": {
     "duration": 0.010584,
     "end_time": "2024-07-30T08:35:41.979481",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.968897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle relative file/directory paths\n",
    "\n",
    "deposits_filename = os.path.join(data_dir, deposits_filename)\n",
    "regions_filename = os.path.join(data_dir, regions_filename)\n",
    "agegrid_dir = os.path.join(data_dir, agegrid_dir)\n",
    "sedthick_dir = os.path.join(data_dir, sedthick_dir)\n",
    "carbonate_dir = os.path.join(data_dir, carbonate_dir)\n",
    "co2_dir = os.path.join(data_dir, co2_dir)\n",
    "crustal_thickness_dir = os.path.join(data_dir, crustal_thickness_dir)\n",
    "subducted_quantities_dir = os.path.join(data_dir, subducted_quantities_dir)\n",
    "erodep_dir = os.path.join(data_dir, erodep_dir)\n",
    "\n",
    "subduction_data_filename = os.path.join(output_dir, \"subducting_plate_data.csv\")\n",
    "study_area_dir = os.path.join(output_dir, \"study_area_polygons\")\n",
    "output_filename = os.path.join(output_dir, \"training_data_global.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad4521b6",
   "metadata": {
    "papermill": {
     "duration": 0.003697,
     "end_time": "2024-07-30T08:35:41.987012",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.983315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Subducting plate data\n",
    "\n",
    "This cell will extract the subduction kinematics data from the plate model, along with datasets relating to the subducting oceanic plate: seafloor age, sediment and carbonate thickness, etc.\n",
    "However, if this data has already been extracted by another notebook and `overwrite` has not been set to `True`, then the data will be read from that file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61eb7d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:35:41.995547Z",
     "iopub.status.busy": "2024-07-30T08:35:41.995269Z",
     "iopub.status.idle": "2024-07-30T08:35:53.395801Z",
     "shell.execute_reply": "2024-07-30T08:35:53.395005Z"
    },
    "papermill": {
     "duration": 11.407164,
     "end_time": "2024-07-30T08:35:53.397761",
     "exception": false,
     "start_time": "2024-07-30T08:35:41.990597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    subduction_data_filename is not None and os.path.isfile(subduction_data_filename)\n",
    ") and (not overwrite):\n",
    "    subduction_data = pd.read_csv(subduction_data_filename)\n",
    "else:\n",
    "    subduction_data = run_calculate_convergence(\n",
    "        nprocs=n_jobs,\n",
    "        min_time=min(times),\n",
    "        max_time=max(times),\n",
    "        plate_reconstruction=plate_model,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    subduction_data = run_coregister_ocean_rasters(\n",
    "        nprocs=n_jobs,\n",
    "        times=times,\n",
    "        input_data=subduction_data,\n",
    "        agegrid_dir=agegrid_dir,\n",
    "        plate_reconstruction=plate_model,\n",
    "        sedthick_dir=sedthick_dir,\n",
    "        carbonate_dir=carbonate_dir,\n",
    "        co2_dir=co2_dir,\n",
    "        subducted_thickness_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"plate_thickness\",\n",
    "        ),\n",
    "        subducted_sediments_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"sediment_thickness\",\n",
    "        ),\n",
    "        subducted_carbonates_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"carbonate_thickness\",\n",
    "        ),\n",
    "        subducted_water_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"water_thickness\",\n",
    "        ),\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    subduction_data[\"plate_thickness (m)\"] = plate_isotherm_depth(\n",
    "        subduction_data[\"seafloor_age (Ma)\"],\n",
    "        maxiter=100,\n",
    "    )\n",
    "    subduction_data = calculate_water_thickness(data=subduction_data)\n",
    "    subduction_data = calculate_carbon(subduction_data)\n",
    "    subduction_data = calculate_slab_flux(subduction_data)\n",
    "    subduction_data = calculate_slab_dip(subduction_data)\n",
    "    subduction_data = extract_subducted_thickness(\n",
    "        subduction_data,\n",
    "        plate_reconstruction=plate_model,\n",
    "    )\n",
    "\n",
    "    if subduction_data_filename is not None:\n",
    "        subduction_data.to_csv(subduction_data_filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c13f1fcf",
   "metadata": {
    "papermill": {
     "duration": 0.004837,
     "end_time": "2024-07-30T08:35:53.408419",
     "exception": false,
     "start_time": "2024-07-30T08:35:53.403582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create study area polygons along subduction zones\n",
    "\n",
    "Here we define our study area as all points on the overriding plate within a certain distance of the subduction zone (by default, $6 \\degree, \\approx 660\\mathrm{km}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9007fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:35:53.418629Z",
     "iopub.status.busy": "2024-07-30T08:35:53.418398Z",
     "iopub.status.idle": "2024-07-30T08:35:53.422010Z",
     "shell.execute_reply": "2024-07-30T08:35:53.421512Z"
    },
    "papermill": {
     "duration": 0.010395,
     "end_time": "2024-07-30T08:35:53.423465",
     "exception": false,
     "start_time": "2024-07-30T08:35:53.413070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib.create_study_area_polygons import DEFAULT_SZ_BUFFER_DISTANCE\n",
    "\n",
    "buffer_distance = DEFAULT_SZ_BUFFER_DISTANCE  # 6.0\n",
    "\n",
    "if overwrite or not os.path.isdir(study_area_dir):\n",
    "    run_create_study_area_polygons(\n",
    "        nprocs=n_jobs,\n",
    "        times=times,\n",
    "        plate_reconstruction=plate_model,\n",
    "        output_dir=study_area_dir,\n",
    "        buffer_distance=buffer_distance,\n",
    "        verbose=verbose,\n",
    "        return_output=False,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd820aa6",
   "metadata": {
    "papermill": {
     "duration": 0.004514,
     "end_time": "2024-07-30T08:35:53.432684",
     "exception": false,
     "start_time": "2024-07-30T08:35:53.428170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate random unlabelled data points\n",
    "\n",
    "The unlabelled set is created by generating uniformly-distributed random points within the polygons created in the previous cell. To change the number of points generated at each timestep, modify the `num_unlabelled` parameter defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469bcdb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:35:53.442578Z",
     "iopub.status.busy": "2024-07-30T08:35:53.442359Z",
     "iopub.status.idle": "2024-07-30T09:32:57.338241Z",
     "shell.execute_reply": "2024-07-30T09:32:57.337589Z"
    },
    "papermill": {
     "duration": 3423.902941,
     "end_time": "2024-07-30T09:32:57.340145",
     "exception": false,
     "start_time": "2024-07-30T08:35:53.437204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unlabelled = generate_unlabelled_points(\n",
    "    times=times,\n",
    "    input_dir=study_area_dir,\n",
    "    num=num_unlabelled,\n",
    "    threads=n_jobs,\n",
    "    seed=random_seed,\n",
    "    plate_reconstruction=plate_model,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8775853",
   "metadata": {
    "papermill": {
     "duration": 0.003788,
     "end_time": "2024-07-30T09:32:57.348959",
     "exception": false,
     "start_time": "2024-07-30T09:32:57.345171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Combine labelled deposit/non-deposit data with random unlabelled data\n",
    "\n",
    "The function below wrangles the points generated in the previous cell into the same format as the deposit location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f002d601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T09:32:57.358780Z",
     "iopub.status.busy": "2024-07-30T09:32:57.358318Z",
     "iopub.status.idle": "2024-07-30T09:37:20.231616Z",
     "shell.execute_reply": "2024-07-30T09:37:20.230757Z"
    },
    "papermill": {
     "duration": 262.880779,
     "end_time": "2024-07-30T09:37:20.233725",
     "exception": false,
     "start_time": "2024-07-30T09:32:57.352946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_points = combine_point_data(\n",
    "    deposit_data=deposits_filename,\n",
    "    unlabelled_data=unlabelled,\n",
    "    plate_reconstruction=plate_model,\n",
    "    study_area_dir=study_area_dir,\n",
    "    min_time=min(times),\n",
    "    max_time=max(times),\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")\n",
    "del unlabelled\n",
    "combined_points = combined_points.dropna(subset=[\"present_lon\", \"present_lat\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5da1c1a7",
   "metadata": {
    "papermill": {
     "duration": 0.004834,
     "end_time": "2024-07-30T09:37:20.246312",
     "exception": false,
     "start_time": "2024-07-30T09:37:20.241478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign subduction data to point deposit/non-deposit/unlabelled data\n",
    "\n",
    "Here we assign the appropriate values for the subduction-related parameters (kinematics, seafloor age, etc.) to the deposit sites and random locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f932fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T09:37:20.258265Z",
     "iopub.status.busy": "2024-07-30T09:37:20.258013Z",
     "iopub.status.idle": "2024-07-30T09:37:29.977923Z",
     "shell.execute_reply": "2024-07-30T09:37:29.977061Z"
    },
    "papermill": {
     "duration": 9.728347,
     "end_time": "2024-07-30T09:37:29.979990",
     "exception": false,
     "start_time": "2024-07-30T09:37:20.251643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = run_coregister_combined_point_data(\n",
    "    point_data=combined_points,\n",
    "    subduction_data=subduction_data,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")\n",
    "del combined_points, subduction_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "049e3a37",
   "metadata": {
    "papermill": {
     "duration": 0.005617,
     "end_time": "2024-07-30T09:37:29.991882",
     "exception": false,
     "start_time": "2024-07-30T09:37:29.986265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign crustal thickness data to point data\n",
    "\n",
    "This cell extracts the overriding plate thickness at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ca008c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T09:37:30.004093Z",
     "iopub.status.busy": "2024-07-30T09:37:30.003815Z",
     "iopub.status.idle": "2024-07-30T09:37:35.693595Z",
     "shell.execute_reply": "2024-07-30T09:37:35.692749Z"
    },
    "papermill": {
     "duration": 5.698217,
     "end_time": "2024-07-30T09:37:35.695644",
     "exception": false,
     "start_time": "2024-07-30T09:37:29.997427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = run_coregister_crustal_thickness(\n",
    "    point_data=coregistered_data,\n",
    "    input_dir=crustal_thickness_dir,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930468be",
   "metadata": {
    "papermill": {
     "duration": 0.0056,
     "end_time": "2024-07-30T09:37:35.707228",
     "exception": false,
     "start_time": "2024-07-30T09:37:35.701628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculate cumulative erosion\n",
    "\n",
    "Here we calculate the cumulative erosion experienced by each deposit/random point since its time of formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15fe4a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T09:37:35.718148Z",
     "iopub.status.busy": "2024-07-30T09:37:35.717915Z",
     "iopub.status.idle": "2024-07-30T09:38:27.884727Z",
     "shell.execute_reply": "2024-07-30T09:38:27.883939Z"
    },
    "papermill": {
     "duration": 52.174238,
     "end_time": "2024-07-30T09:38:27.886737",
     "exception": false,
     "start_time": "2024-07-30T09:37:35.712499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = calculate_erodep(\n",
    "    coregistered_data,\n",
    "    input_dir=erodep_dir,\n",
    "    n_jobs=n_jobs,\n",
    "    column_name=\"erosion (m)\",\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0d00f",
   "metadata": {
    "papermill": {
     "duration": 0.005639,
     "end_time": "2024-07-30T09:38:27.899856",
     "exception": false,
     "start_time": "2024-07-30T09:38:27.894217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign data to regions\n",
    "\n",
    "To divide the data into individual regions for the later analysis, we use the `regions_filename` defined earlier, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a93d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T09:38:27.910974Z",
     "iopub.status.busy": "2024-07-30T09:38:27.910583Z",
     "iopub.status.idle": "2024-07-30T09:38:28.066165Z",
     "shell.execute_reply": "2024-07-30T09:38:28.065483Z"
    },
    "papermill": {
     "duration": 0.162872,
     "end_time": "2024-07-30T09:38:28.067990",
     "exception": false,
     "start_time": "2024-07-30T09:38:27.905118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if regions_filename is not None and os.path.isfile(regions_filename):\n",
    "    points = gpd.GeoSeries.from_xy(\n",
    "        coregistered_data[\"present_lon\"],\n",
    "        coregistered_data[\"present_lat\"],\n",
    "        index=coregistered_data.index,\n",
    "    )\n",
    "    coregistered_data[\"region\"] = assign_regions(\n",
    "        points,\n",
    "        regions=regions_filename,\n",
    "    )\n",
    "    del points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be29d4",
   "metadata": {
    "papermill": {
     "duration": 0.004572,
     "end_time": "2024-07-30T09:38:28.077609",
     "exception": false,
     "start_time": "2024-07-30T09:38:28.073037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save to file\n",
    "\n",
    "Finally, we write the dataset to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3de5c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T09:38:28.089881Z",
     "iopub.status.busy": "2024-07-30T09:38:28.089622Z",
     "iopub.status.idle": "2024-07-30T09:38:30.086081Z",
     "shell.execute_reply": "2024-07-30T09:38:30.085566Z"
    },
    "papermill": {
     "duration": 2.005357,
     "end_time": "2024-07-30T09:38:30.087559",
     "exception": false,
     "start_time": "2024-07-30T09:38:28.082202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region          label     \n",
       "East Asia       negative         7\n",
       "                positive         5\n",
       "                unlabelled    4734\n",
       "North America   negative        45\n",
       "                positive       257\n",
       "                unlabelled    7890\n",
       "Other           negative       203\n",
       "                positive         1\n",
       "                unlabelled    3741\n",
       "South America   negative      1096\n",
       "                positive       211\n",
       "                unlabelled    5709\n",
       "Southeast Asia  negative         4\n",
       "                positive        55\n",
       "                unlabelled    7811\n",
       "Tethys          negative        20\n",
       "                positive        61\n",
       "                unlabelled    5922\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coregistered_data.to_csv(output_filename, index=False)\n",
    "\n",
    "coregistered_data.groupby([\"region\", \"label\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78df4c5",
   "metadata": {
    "papermill": {
     "duration": 0.005061,
     "end_time": "2024-07-30T09:38:30.097556",
     "exception": false,
     "start_time": "2024-07-30T09:38:30.092495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3822.744958,
   "end_time": "2024-07-30T09:38:33.033229",
   "environment_variables": {},
   "exception": null,
   "input_path": "00c-extract_training_data_global.ipynb",
   "output_path": "00c-extract_training_data_global.ipynb",
   "parameters": {},
   "start_time": "2024-07-30T08:34:50.288271",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}