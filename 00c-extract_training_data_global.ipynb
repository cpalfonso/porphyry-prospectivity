{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e474db9",
   "metadata": {
    "papermill": {
     "duration": 0.007025,
     "end_time": "2024-06-20T11:22:43.012851",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.005826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract training data\n",
    "\n",
    "This notebook will extract plate kinematic data from a plate model and other data from the `source_data` directory, writing the resulting dataset to a CSV file which can then be used to train the models in the following notebooks (`01*.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbeab9",
   "metadata": {
    "papermill": {
     "duration": 0.00458,
     "end_time": "2024-06-20T11:22:43.022139",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.017559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook options\n",
    "\n",
    "These cells set some of the important variables and definitions used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab57c3d5",
   "metadata": {
    "papermill": {
     "duration": 0.004361,
     "end_time": "2024-06-20T11:22:43.030954",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.026593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Select plate model\n",
    "\n",
    "To use the plate model from the published paper (Alfonso et al., 2024), set `use_provided_plate_model` to `True`. Otherwise, leave `use_provided_plate_model` as `False` and set `plate_model_name` to a valid model name for the [`plate-model-manager`](https://github.com/michaelchin/plate-model-manager/blob/4f66423b53950bf42f5dac1228e61fd1e19fdf6e/models.json) package, or set `plate_model_name` to `None` and place GPlates files in a directory named `plate_model`.\n",
    "\n",
    "| `use_provided_plate_model` | `plate_model_name` | result |\n",
    "| - | - | - |\n",
    "| `True` | Any | Use Alfonso et al., 2024 model |\n",
    "| `False` | Model name string (e.g. `\"muller2022\"`) | Use specified plate model |\n",
    "| `False` | `None` | Use files in `plate_model` directory |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7b1534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:22:43.040817Z",
     "iopub.status.busy": "2024-06-20T11:22:43.040524Z",
     "iopub.status.idle": "2024-06-20T11:22:43.046553Z",
     "shell.execute_reply": "2024-06-20T11:22:43.046038Z"
    },
    "papermill": {
     "duration": 0.012847,
     "end_time": "2024-06-20T11:22:43.048052",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.035205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_provided_plate_model = True\n",
    "plate_model_name = \"muller2022\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1896136",
   "metadata": {
    "papermill": {
     "duration": 0.004042,
     "end_time": "2024-06-20T11:22:43.056454",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.052412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Set other parameters\n",
    "\n",
    "Perhaps the most important options here are `n_jobs` and `max_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0885a686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:22:43.064551Z",
     "iopub.status.busy": "2024-06-20T11:22:43.064349Z",
     "iopub.status.idle": "2024-06-20T11:22:43.067447Z",
     "shell.execute_reply": "2024-06-20T11:22:43.066939Z"
    },
    "papermill": {
     "duration": 0.008714,
     "end_time": "2024-06-20T11:22:43.068784",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.060070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Allow reproducibility of randomised results\n",
    "random_seed = 1234\n",
    "\n",
    "# Number of processes to use\n",
    "n_jobs = 4\n",
    "\n",
    "# Overwrite any existing output files\n",
    "overwrite = False\n",
    "\n",
    "# Timespan for analysis\n",
    "min_time = 0\n",
    "max_time = 170\n",
    "\n",
    "# Control verbosity level of logging output\n",
    "verbose = False\n",
    "\n",
    "# Number of unlabelled points to generate\n",
    "num_unlabelled = 200  # per timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee294e4e",
   "metadata": {
    "papermill": {
     "duration": 0.003644,
     "end_time": "2024-06-20T11:22:43.076035",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.072391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If any of the following exist as environment variables, they will replace the values defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67868847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:22:43.084217Z",
     "iopub.status.busy": "2024-06-20T11:22:43.084032Z",
     "iopub.status.idle": "2024-06-20T11:22:43.087830Z",
     "shell.execute_reply": "2024-06-20T11:22:43.087420Z"
    },
    "papermill": {
     "duration": 0.009783,
     "end_time": "2024-06-20T11:22:43.089246",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.079463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Override above values with environment variables, if they exist\n",
    "n_jobs = int(os.environ.get(\"N_JOBS\", n_jobs))\n",
    "overwrite = bool(int(os.environ.get(\"OVERWRITE\", overwrite)))\n",
    "min_time = int(os.environ.get(\"MIN_TIME\", min_time))\n",
    "max_time = int(os.environ.get(\"MAX_TIME\", max_time))\n",
    "verbose = bool(int(os.environ.get(\"VERBOSE\", verbose)))\n",
    "num_unlabelled = int(os.environ.get(\"NUM_UNLABELLED\", num_unlabelled))\n",
    "\n",
    "times = range(min_time, max_time + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa8fc32",
   "metadata": {
    "papermill": {
     "duration": 0.003778,
     "end_time": "2024-06-20T11:22:43.096751",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.092973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook setup\n",
    "\n",
    "Imports, definitions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1302b",
   "metadata": {
    "papermill": {
     "duration": 0.003659,
     "end_time": "2024-06-20T11:22:43.103932",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.100273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92a09be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:22:43.111886Z",
     "iopub.status.busy": "2024-06-20T11:22:43.111724Z",
     "iopub.status.idle": "2024-06-20T11:22:47.485900Z",
     "shell.execute_reply": "2024-06-20T11:22:47.485243Z"
    },
    "papermill": {
     "duration": 4.38106,
     "end_time": "2024-06-20T11:22:47.488506",
     "exception": false,
     "start_time": "2024-06-20T11:22:43.107446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONWARNINGS=ignore::UserWarning\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from gplately.tools import plate_isotherm_depth\n",
    "\n",
    "from lib.assign_regions import assign_regions\n",
    "from lib.calculate_convergence import run_calculate_convergence\n",
    "from lib.check_files import (\n",
    "    check_source_data,\n",
    "    check_plate_model,\n",
    ")\n",
    "from lib.combine_point_data import combine_point_data\n",
    "from lib.coregister_combined_point_data import run_coregister_combined_point_data\n",
    "from lib.coregister_crustal_thickness import run_coregister_crustal_thickness\n",
    "from lib.coregister_ocean_rasters import run_coregister_ocean_rasters\n",
    "from lib.create_study_area_polygons import run_create_study_area_polygons\n",
    "from lib.erodep import calculate_erodep\n",
    "from lib.generate_unlabelled_points import generate_unlabelled_points\n",
    "from lib.misc import calculate_slab_flux\n",
    "from lib.plate_models import get_plate_reconstruction\n",
    "from lib.slab_dip import calculate_slab_dip\n",
    "from lib.water import calculate_water_thickness\n",
    "\n",
    "# Suppress occasional joblib warnings\n",
    "%env PYTHONWARNINGS=ignore::UserWarning\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "880580d1",
   "metadata": {
    "papermill": {
     "duration": 0.00716,
     "end_time": "2024-06-20T11:22:47.503812",
     "exception": false,
     "start_time": "2024-06-20T11:22:47.496652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Input and output files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e17a79",
   "metadata": {
    "papermill": {
     "duration": 0.005254,
     "end_time": "2024-06-20T11:22:47.514499",
     "exception": false,
     "start_time": "2024-06-20T11:22:47.509245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If necessary, the plate model will be downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60656f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:22:47.524813Z",
     "iopub.status.busy": "2024-06-20T11:22:47.524558Z",
     "iopub.status.idle": "2024-06-20T11:23:32.205787Z",
     "shell.execute_reply": "2024-06-20T11:23:32.205212Z"
    },
    "papermill": {
     "duration": 44.688322,
     "end_time": "2024-06-20T11:23:32.207321",
     "exception": false,
     "start_time": "2024-06-20T11:22:47.518999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_model_dir = \"plate_model\"\n",
    "if use_provided_plate_model:\n",
    "    check_plate_model(plate_model_dir, verbose=True)\n",
    "    plate_model_name = None\n",
    "plate_model = get_plate_reconstruction(\n",
    "    model_name=plate_model_name,\n",
    "    model_dir=plate_model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6b313",
   "metadata": {
    "papermill": {
     "duration": 0.003763,
     "end_time": "2024-06-20T11:23:32.215310",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.211547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The directory containing the datasets to be extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb00231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:23:32.223903Z",
     "iopub.status.busy": "2024-06-20T11:23:32.223612Z",
     "iopub.status.idle": "2024-06-20T11:23:32.227562Z",
     "shell.execute_reply": "2024-06-20T11:23:32.226818Z"
    },
    "papermill": {
     "duration": 0.010423,
     "end_time": "2024-06-20T11:23:32.229330",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.218907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"source_data\"\n",
    "data_dir = check_source_data(data_dir, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbcd39d",
   "metadata": {
    "papermill": {
     "duration": 0.003982,
     "end_time": "2024-06-20T11:23:32.236909",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.232927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Output files will be created in this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cdb93cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:23:32.247715Z",
     "iopub.status.busy": "2024-06-20T11:23:32.247401Z",
     "iopub.status.idle": "2024-06-20T11:23:32.250811Z",
     "shell.execute_reply": "2024-06-20T11:23:32.250255Z"
    },
    "papermill": {
     "duration": 0.009794,
     "end_time": "2024-06-20T11:23:32.252321",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.242527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"extracted_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489edaa8",
   "metadata": {
    "papermill": {
     "duration": 0.00397,
     "end_time": "2024-06-20T11:23:32.260200",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.256230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following input directories are all relative to `data_dir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d7de4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:23:32.268661Z",
     "iopub.status.busy": "2024-06-20T11:23:32.268406Z",
     "iopub.status.idle": "2024-06-20T11:23:32.272149Z",
     "shell.execute_reply": "2024-06-20T11:23:32.271732Z"
    },
    "papermill": {
     "duration": 0.009439,
     "end_time": "2024-06-20T11:23:32.273521",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.264082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CSV file with known deposits; columns:\n",
    "# lon, lat, age (Ma)\n",
    "deposits_filename = \"deposit_data_global.csv\"\n",
    "\n",
    "# If desired, categorise deposits according to location\n",
    "# Should be a shapefile or GeoJSON containing polygons\n",
    "# with a 'region' attribute\n",
    "regions_filename = \"regions.geojson\"\n",
    "\n",
    "# Seafloor age grid directory\n",
    "# Filename format 'seafloor_age_{time}Ma.nc'\n",
    "agegrid_dir = \"AgeGrids\"\n",
    "\n",
    "# Seafloor sediment thickness directory\n",
    "# Filename format 'sediment_thickness_{time}Ma.nc'\n",
    "sedthick_dir = \"SedimentThickness\"\n",
    "\n",
    "# Seafloor carbonate sediment thickness directory\n",
    "# Filename format 'carbonate_thickness_{time}Ma.nc'\n",
    "carbonate_dir = \"CarbonateThickness\"\n",
    "\n",
    "# Oceanic crustal CO2 density directory\n",
    "# Filename format 'crustal_co2_{time}Ma.nc'\n",
    "co2_dir = \"CrustalCO2\"\n",
    "\n",
    "# Overriding plate thickness directory\n",
    "# Filename format 'crustal_thickness_{time}Ma.nc'\n",
    "crustal_thickness_dir = \"CrustalThickness\"\n",
    "\n",
    "# Cumulative subducted sediments/carbonates/etc. directory\n",
    "# Filename format 'sediment_thickness/cumulative_density_{time}Ma.nc',\n",
    "# 'carbonate_thickness/cumulative_density_{time}Ma.nc', etc.\n",
    "subducted_quantities_dir = \"SubductedQuantities\"\n",
    "\n",
    "# Erosion/deposition rate directory\n",
    "# Filename format 'erosion_deposition_{time}Ma.nc'\n",
    "erodep_dir = \"ErosionDeposition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32544941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:23:32.281697Z",
     "iopub.status.busy": "2024-06-20T11:23:32.281499Z",
     "iopub.status.idle": "2024-06-20T11:23:32.285648Z",
     "shell.execute_reply": "2024-06-20T11:23:32.285224Z"
    },
    "papermill": {
     "duration": 0.009674,
     "end_time": "2024-06-20T11:23:32.286939",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.277265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle relative file/directory paths\n",
    "\n",
    "deposits_filename = os.path.join(data_dir, deposits_filename)\n",
    "regions_filename = os.path.join(data_dir, regions_filename)\n",
    "agegrid_dir = os.path.join(data_dir, agegrid_dir)\n",
    "sedthick_dir = os.path.join(data_dir, sedthick_dir)\n",
    "carbonate_dir = os.path.join(data_dir, carbonate_dir)\n",
    "co2_dir = os.path.join(data_dir, co2_dir)\n",
    "crustal_thickness_dir = os.path.join(data_dir, crustal_thickness_dir)\n",
    "subducted_quantities_dir = os.path.join(data_dir, subducted_quantities_dir)\n",
    "erodep_dir = os.path.join(data_dir, erodep_dir)\n",
    "\n",
    "subduction_data_filename = os.path.join(output_dir, \"subducting_plate_data.csv\")\n",
    "study_area_dir = os.path.join(output_dir, \"study_area_polygons\")\n",
    "output_filename = os.path.join(output_dir, \"training_data_global.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad4521b6",
   "metadata": {
    "papermill": {
     "duration": 0.003595,
     "end_time": "2024-06-20T11:23:32.294562",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.290967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Subducting plate data\n",
    "\n",
    "This cell will extract the subduction kinematics data from the plate model, along with datasets relating to the subducting oceanic plate: seafloor age, sediment and carbonate thickness, etc.\n",
    "However, if this data has already been extracted by another notebook and `overwrite` has not been set to `True`, then the data will be read from that file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61eb7d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:23:32.302689Z",
     "iopub.status.busy": "2024-06-20T11:23:32.302490Z",
     "iopub.status.idle": "2024-06-20T11:23:33.528256Z",
     "shell.execute_reply": "2024-06-20T11:23:33.527616Z"
    },
    "papermill": {
     "duration": 1.231745,
     "end_time": "2024-06-20T11:23:33.529898",
     "exception": false,
     "start_time": "2024-06-20T11:23:32.298153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    subduction_data_filename is not None and os.path.isfile(subduction_data_filename)\n",
    ") and (not overwrite):\n",
    "    subduction_data = pd.read_csv(subduction_data_filename)\n",
    "else:\n",
    "    subduction_data = run_calculate_convergence(\n",
    "        nprocs=n_jobs,\n",
    "        min_time=min(times),\n",
    "        max_time=max(times),\n",
    "        plate_reconstruction=plate_model,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    subduction_data = run_coregister_ocean_rasters(\n",
    "        nprocs=n_jobs,\n",
    "        times=times,\n",
    "        input_data=subduction_data,\n",
    "        agegrid_dir=agegrid_dir,\n",
    "        plate_reconstruction=plate_model,\n",
    "        sedthick_dir=sedthick_dir,\n",
    "        carbonate_dir=carbonate_dir,\n",
    "        co2_dir=co2_dir,\n",
    "        subducted_thickness_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"plate_thickness\",\n",
    "        ),\n",
    "        subducted_sediments_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"sediment_thickness\",\n",
    "        ),\n",
    "        subducted_carbonates_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"carbonate_thickness\",\n",
    "        ),\n",
    "        subducted_water_dir=os.path.join(\n",
    "            subducted_quantities_dir,\n",
    "            \"water_thickness\",\n",
    "        ),\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    subduction_data[\"plate_thickness (m)\"] = plate_isotherm_depth(\n",
    "        subduction_data[\"seafloor_age (Ma)\"],\n",
    "        maxiter=100,\n",
    "    )\n",
    "    subduction_data = calculate_water_thickness(data=subduction_data)\n",
    "    subduction_data = calculate_slab_flux(subduction_data)\n",
    "    subduction_data = calculate_slab_dip(subduction_data)\n",
    "\n",
    "    if subduction_data_filename is not None:\n",
    "        subduction_data.to_csv(subduction_data_filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c13f1fcf",
   "metadata": {
    "papermill": {
     "duration": 0.004586,
     "end_time": "2024-06-20T11:23:33.539471",
     "exception": false,
     "start_time": "2024-06-20T11:23:33.534885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create study area polygons along subduction zones\n",
    "\n",
    "Here we define our study area as all points on the overriding plate within a certain distance of the subduction zone (by default, $6 \\degree, \\approx 660\\mathrm{km}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9007fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:23:33.549293Z",
     "iopub.status.busy": "2024-06-20T11:23:33.549061Z",
     "iopub.status.idle": "2024-06-20T11:23:33.552513Z",
     "shell.execute_reply": "2024-06-20T11:23:33.552034Z"
    },
    "papermill": {
     "duration": 0.010054,
     "end_time": "2024-06-20T11:23:33.553966",
     "exception": false,
     "start_time": "2024-06-20T11:23:33.543912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib.create_study_area_polygons import DEFAULT_SZ_BUFFER_DISTANCE\n",
    "\n",
    "buffer_distance = DEFAULT_SZ_BUFFER_DISTANCE  # 6.0\n",
    "\n",
    "if overwrite or not os.path.isdir(study_area_dir):\n",
    "    run_create_study_area_polygons(\n",
    "        nprocs=n_jobs,\n",
    "        times=times,\n",
    "        plate_reconstruction=plate_model,\n",
    "        output_dir=study_area_dir,\n",
    "        buffer_distance=buffer_distance,\n",
    "        verbose=verbose,\n",
    "        return_output=False,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd820aa6",
   "metadata": {
    "papermill": {
     "duration": 0.004558,
     "end_time": "2024-06-20T11:23:33.563062",
     "exception": false,
     "start_time": "2024-06-20T11:23:33.558504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate random unlabelled data points\n",
    "\n",
    "The unlabelled set is created by generating uniformly-distributed random points within the polygons created in the previous cell. To change the number of points generated at each timestep, modify the `num_unlabelled` parameter defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469bcdb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T11:23:33.572337Z",
     "iopub.status.busy": "2024-06-20T11:23:33.572051Z",
     "iopub.status.idle": "2024-06-20T12:19:16.369362Z",
     "shell.execute_reply": "2024-06-20T12:19:16.368765Z"
    },
    "papermill": {
     "duration": 3342.803628,
     "end_time": "2024-06-20T12:19:16.371139",
     "exception": false,
     "start_time": "2024-06-20T11:23:33.567511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unlabelled = generate_unlabelled_points(\n",
    "    times=times,\n",
    "    input_dir=study_area_dir,\n",
    "    num=num_unlabelled,\n",
    "    threads=n_jobs,\n",
    "    seed=random_seed,\n",
    "    plate_reconstruction=plate_model,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8775853",
   "metadata": {
    "papermill": {
     "duration": 0.00382,
     "end_time": "2024-06-20T12:19:16.379301",
     "exception": false,
     "start_time": "2024-06-20T12:19:16.375481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Combine labelled deposit/non-deposit data with random unlabelled data\n",
    "\n",
    "The function below wrangles the points generated in the previous cell into the same format as the deposit location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f002d601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:19:16.388338Z",
     "iopub.status.busy": "2024-06-20T12:19:16.388030Z",
     "iopub.status.idle": "2024-06-20T12:23:31.994063Z",
     "shell.execute_reply": "2024-06-20T12:23:31.993383Z"
    },
    "papermill": {
     "duration": 255.612534,
     "end_time": "2024-06-20T12:23:31.995757",
     "exception": false,
     "start_time": "2024-06-20T12:19:16.383223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_points = combine_point_data(\n",
    "    deposit_data=deposits_filename,\n",
    "    unlabelled_data=unlabelled,\n",
    "    plate_reconstruction=plate_model,\n",
    "    study_area_dir=study_area_dir,\n",
    "    min_time=min(times),\n",
    "    max_time=max(times),\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")\n",
    "del unlabelled\n",
    "combined_points = combined_points.dropna(subset=[\"present_lon\", \"present_lat\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5da1c1a7",
   "metadata": {
    "papermill": {
     "duration": 0.006117,
     "end_time": "2024-06-20T12:23:32.011436",
     "exception": false,
     "start_time": "2024-06-20T12:23:32.005319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign subduction data to point deposit/non-deposit/unlabelled data\n",
    "\n",
    "Here we assign the appropriate values for the subduction-related parameters (kinematics, seafloor age, etc.) to the deposit sites and random locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f932fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:23:32.021855Z",
     "iopub.status.busy": "2024-06-20T12:23:32.021619Z",
     "iopub.status.idle": "2024-06-20T12:23:37.290442Z",
     "shell.execute_reply": "2024-06-20T12:23:37.289522Z"
    },
    "papermill": {
     "duration": 5.276208,
     "end_time": "2024-06-20T12:23:37.292229",
     "exception": false,
     "start_time": "2024-06-20T12:23:32.016021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = run_coregister_combined_point_data(\n",
    "    point_data=combined_points,\n",
    "    subduction_data=subduction_data,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")\n",
    "del combined_points, subduction_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "049e3a37",
   "metadata": {
    "papermill": {
     "duration": 0.005947,
     "end_time": "2024-06-20T12:23:37.305986",
     "exception": false,
     "start_time": "2024-06-20T12:23:37.300039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign crustal thickness data to point data\n",
    "\n",
    "This cell extracts the overriding plate thickness at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ca008c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:23:37.318623Z",
     "iopub.status.busy": "2024-06-20T12:23:37.318353Z",
     "iopub.status.idle": "2024-06-20T12:23:42.605235Z",
     "shell.execute_reply": "2024-06-20T12:23:42.604534Z"
    },
    "papermill": {
     "duration": 5.295381,
     "end_time": "2024-06-20T12:23:42.607067",
     "exception": false,
     "start_time": "2024-06-20T12:23:37.311686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = run_coregister_crustal_thickness(\n",
    "    point_data=coregistered_data,\n",
    "    input_dir=crustal_thickness_dir,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930468be",
   "metadata": {
    "papermill": {
     "duration": 0.009668,
     "end_time": "2024-06-20T12:23:42.626713",
     "exception": false,
     "start_time": "2024-06-20T12:23:42.617045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculate cumulative erosion\n",
    "\n",
    "Here we calculate the cumulative erosion experienced by each deposit/random point since its time of formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15fe4a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:23:42.640606Z",
     "iopub.status.busy": "2024-06-20T12:23:42.640355Z",
     "iopub.status.idle": "2024-06-20T12:24:33.186726Z",
     "shell.execute_reply": "2024-06-20T12:24:33.186080Z"
    },
    "papermill": {
     "duration": 50.553836,
     "end_time": "2024-06-20T12:24:33.188421",
     "exception": false,
     "start_time": "2024-06-20T12:23:42.634585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coregistered_data = calculate_erodep(\n",
    "    coregistered_data,\n",
    "    input_dir=erodep_dir,\n",
    "    n_jobs=n_jobs,\n",
    "    column_name=\"erosion (m)\",\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0d00f",
   "metadata": {
    "papermill": {
     "duration": 0.004756,
     "end_time": "2024-06-20T12:24:33.198309",
     "exception": false,
     "start_time": "2024-06-20T12:24:33.193553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign data to regions\n",
    "\n",
    "To divide the data into individual regions for the later analysis, we use the `regions_filename` defined earlier, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a93d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:24:33.208623Z",
     "iopub.status.busy": "2024-06-20T12:24:33.208264Z",
     "iopub.status.idle": "2024-06-20T12:24:33.373720Z",
     "shell.execute_reply": "2024-06-20T12:24:33.373040Z"
    },
    "papermill": {
     "duration": 0.172526,
     "end_time": "2024-06-20T12:24:33.375513",
     "exception": false,
     "start_time": "2024-06-20T12:24:33.202987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if regions_filename is not None and os.path.isfile(regions_filename):\n",
    "    points = gpd.GeoSeries.from_xy(\n",
    "        coregistered_data[\"present_lon\"],\n",
    "        coregistered_data[\"present_lat\"],\n",
    "        index=coregistered_data.index,\n",
    "    )\n",
    "    coregistered_data[\"region\"] = assign_regions(\n",
    "        points,\n",
    "        regions=regions_filename,\n",
    "    )\n",
    "    del points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be29d4",
   "metadata": {
    "papermill": {
     "duration": 0.004584,
     "end_time": "2024-06-20T12:24:33.385188",
     "exception": false,
     "start_time": "2024-06-20T12:24:33.380604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save to file\n",
    "\n",
    "Finally, we write the dataset to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3de5c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T12:24:33.397613Z",
     "iopub.status.busy": "2024-06-20T12:24:33.397361Z",
     "iopub.status.idle": "2024-06-20T12:24:35.177577Z",
     "shell.execute_reply": "2024-06-20T12:24:35.177051Z"
    },
    "papermill": {
     "duration": 1.78929,
     "end_time": "2024-06-20T12:24:35.179079",
     "exception": false,
     "start_time": "2024-06-20T12:24:33.389789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region          label     \n",
       "East Asia       negative         7\n",
       "                positive         5\n",
       "                unlabelled    4734\n",
       "North America   negative        45\n",
       "                positive       257\n",
       "                unlabelled    7890\n",
       "Other           negative       203\n",
       "                positive         1\n",
       "                unlabelled    3741\n",
       "South America   negative      1096\n",
       "                positive       211\n",
       "                unlabelled    5709\n",
       "Southeast Asia  negative         4\n",
       "                positive        55\n",
       "                unlabelled    7811\n",
       "Tethys          negative        20\n",
       "                positive        61\n",
       "                unlabelled    5922\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coregistered_data.to_csv(output_filename, index=False)\n",
    "\n",
    "coregistered_data.groupby([\"region\", \"label\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78df4c5",
   "metadata": {
    "papermill": {
     "duration": 0.004912,
     "end_time": "2024-06-20T12:24:35.191557",
     "exception": false,
     "start_time": "2024-06-20T12:24:35.186645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3716.259868,
   "end_time": "2024-06-20T12:24:37.925400",
   "environment_variables": {},
   "exception": null,
   "input_path": "00c-extract_training_data_global.ipynb",
   "output_path": "00c-extract_training_data_global.ipynb",
   "parameters": {},
   "start_time": "2024-06-20T11:22:41.665532",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}