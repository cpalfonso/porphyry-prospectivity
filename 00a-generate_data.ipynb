{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243b8854",
   "metadata": {
    "papermill": {
     "duration": 0.005319,
     "end_time": "2025-07-04T08:08:54.131939",
     "exception": false,
     "start_time": "2025-07-04T08:08:54.126620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e496e6e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:08:54.141160Z",
     "iopub.status.busy": "2025-07-04T08:08:54.140894Z",
     "iopub.status.idle": "2025-07-04T08:08:54.145087Z",
     "shell.execute_reply": "2025-07-04T08:08:54.144550Z"
    },
    "papermill": {
     "duration": 0.010172,
     "end_time": "2025-07-04T08:08:54.146412",
     "exception": false,
     "start_time": "2025-07-04T08:08:54.136240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_file = \"notebook_parameters_default.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52ff100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:08:54.155080Z",
     "iopub.status.busy": "2025-07-04T08:08:54.154777Z",
     "iopub.status.idle": "2025-07-04T08:08:58.299423Z",
     "shell.execute_reply": "2025-07-04T08:08:58.298619Z"
    },
    "papermill": {
     "duration": 4.150928,
     "end_time": "2025-07-04T08:08:58.301188",
     "exception": false,
     "start_time": "2025-07-04T08:08:54.150260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import geopandas as gpd\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    import gplately\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygplates\n",
    "import rioxarray\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    from gplately import PlotTopologies\n",
    "\n",
    "from lib.check_files import check_plate_model\n",
    "from lib.extract_data import convert_age_to_depth\n",
    "from lib.extract_data.create_lip_conjugates import create_lip_conjugates\n",
    "from lib.extract_data.crustal_co2 import calculate_crustal_co2\n",
    "from lib.extract_data.crustal_thickness import calculate_crustal_thickness\n",
    "from lib.extract_data.lip_reconstruction import (\n",
    "    calculate_depth_contours,\n",
    "    mp_wrapper_for_shapefile_to_raster,\n",
    "    rotation_LIP_shapefile_and_buffer,\n",
    ")\n",
    "from lib.extract_data.paleobathymetry import (\n",
    "    # add_Pacific_synthetic_seamounts,\n",
    "    calculate_paleobathymetry,\n",
    ")\n",
    "from lib.extract_data.paleotopography import paleotopography_job\n",
    "from lib.extract_data.paleotopography.create_present_day_features import create_present_day_features\n",
    "from lib.extract_data.paleotopography.tween_paleoshorelines_inplace import tween_paleoshorelines_inplace\n",
    "from lib.load_params import get_params\n",
    "from lib.plate_models import get_plate_reconstruction, get_plot_topologies\n",
    "\n",
    "# Sediment thickness modules\n",
    "sedthick_path = os.path.join(\n",
    "    \"submodules\",\n",
    "    \"predicting-sediment-thickness\",\n",
    ")\n",
    "if sedthick_path not in sys.path:\n",
    "    sys.path.insert(0, sedthick_path)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    from ocean_basin_proximity import (\n",
    "        generate_and_write_proximity_data_parallel,\n",
    "        generate_input_points_grid as generate_input_points_grid_seds,\n",
    "    )\n",
    "    from predict_sediment_thickness import (\n",
    "        predict_sedimentation,\n",
    "        write_grd_file,\n",
    "    )\n",
    "\n",
    "# Carbonate thickness modules\n",
    "carbonate_path = os.path.join(\n",
    "    \"submodules\",\n",
    "    \"CarbonateSedimentThickness\",\n",
    ")\n",
    "if carbonate_path not in sys.path:\n",
    "    sys.path.insert(0, carbonate_path)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    from carbonate_sediment_thickness import (\n",
    "        calc_sedimentation,\n",
    "        generate_input_points_grid as generate_input_points_grid_carb,\n",
    "        write_data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ed418c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:08:58.311254Z",
     "iopub.status.busy": "2025-07-04T08:08:58.310812Z",
     "iopub.status.idle": "2025-07-04T08:08:58.333687Z",
     "shell.execute_reply": "2025-07-04T08:08:58.333197Z"
    },
    "papermill": {
     "duration": 0.02953,
     "end_time": "2025-07-04T08:08:58.335067",
     "exception": false,
     "start_time": "2025-07-04T08:08:58.305537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = get_params(config_file, notebook=\"00a\")\n",
    "\n",
    "# Directory for output\n",
    "output_dir = params[\"extracted_data_dir\"]\n",
    "\n",
    "# Overwrite previous outputs\n",
    "overwrite = params[\"overwrite_output\"]\n",
    "overwrite = False\n",
    "\n",
    "# Plate model\n",
    "plate_model_name = params[\"plate_model\"][\"plate_model_name\"]\n",
    "use_provided_plate_model = params[\"plate_model\"][\"use_provided_plate_model\"]\n",
    "\n",
    "# Timespan for analysis\n",
    "min_time = params[\"timespan\"][\"min\"]\n",
    "max_time = params[\"timespan\"][\"max\"]\n",
    "\n",
    "# Number of processes to use\n",
    "n_jobs = params[\"n_jobs\"]\n",
    "\n",
    "# Cleanup working directories\n",
    "# cleanup = params[\"cleanup\"]\n",
    "cleanup = False\n",
    "\n",
    "times = range(min_time, max_time + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38426fb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:08:58.344250Z",
     "iopub.status.busy": "2025-07-04T08:08:58.344001Z",
     "iopub.status.idle": "2025-07-04T08:09:13.078484Z",
     "shell.execute_reply": "2025-07-04T08:09:13.077834Z"
    },
    "papermill": {
     "duration": 14.740811,
     "end_time": "2025-07-04T08:09:13.079874",
     "exception": false,
     "start_time": "2025-07-04T08:08:58.339063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plate_model_dir = \"plate_model\"\n",
    "if use_provided_plate_model:\n",
    "    check_plate_model(plate_model_dir, verbose=True)\n",
    "    plate_model_name = None\n",
    "plate_model = get_plate_reconstruction(\n",
    "    model_name=plate_model_name,\n",
    "    model_dir=plate_model_dir,\n",
    ")\n",
    "\n",
    "if use_provided_plate_model:\n",
    "    coastlines_filenames = [os.path.join(\n",
    "        plate_model_dir,\n",
    "        \"StaticGeometries\",\n",
    "        \"AgeGridInput\",\n",
    "        \"CombinedTerranes.gpml\",\n",
    "    )]\n",
    "    gplot = PlotTopologies(\n",
    "        plate_model,\n",
    "        coastlines=coastlines_filenames,\n",
    "        continents=coastlines_filenames,\n",
    "    )\n",
    "else:\n",
    "    gplot = get_plot_topologies(\n",
    "        model_name=plate_model_name,\n",
    "        model_dir=plate_model_dir,\n",
    "        plate_reconstruction=plate_model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f4467",
   "metadata": {
    "papermill": {
     "duration": 0.003889,
     "end_time": "2025-07-04T08:09:13.087974",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.084085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seafloor age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2faeefbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:13.096275Z",
     "iopub.status.busy": "2025-07-04T08:09:13.096017Z",
     "iopub.status.idle": "2025-07-04T08:09:13.107188Z",
     "shell.execute_reply": "2025-07-04T08:09:13.106359Z"
    },
    "papermill": {
     "duration": 0.017449,
     "end_time": "2025-07-04T08:09:13.109086",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.091637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seafloor_age_output_dir = os.path.join(output_dir, \"SeafloorAge\")\n",
    "spreading_rate_output_dir = os.path.join(output_dir, \"SpreadingRate\")\n",
    "\n",
    "run_seafloor_age = overwrite\n",
    "if not run_seafloor_age:\n",
    "    for time in times:\n",
    "        p = Path(seafloor_age_output_dir, f\"seafloor_age_{time:0.0f}Ma.nc\")\n",
    "        q = Path(spreading_rate_output_dir, f\"spreading_rate_{time:0.0f}Ma.nc\")\n",
    "        if not (p.exists() and q.exists()):\n",
    "            run_seafloor_age = True\n",
    "            break\n",
    "\n",
    "if run_seafloor_age:\n",
    "    seafloor_grid = gplately.SeafloorGrid(\n",
    "        gplot.plate_reconstruction,\n",
    "        gplot,\n",
    "        min_time=min_time,\n",
    "        max_time=max_time,\n",
    "        ridge_time_step=1,\n",
    "        save_directory=os.path.join(output_dir, \"seafloor_age_output\"),\n",
    "    )\n",
    "    seafloor_grid.reconstruct_by_topologies()\n",
    "    for i in [\"SEAFLOOR_AGE\", \"SPREADING_RATE\"]:\n",
    "        seafloor_grid.lat_lon_z_to_netCDF(\n",
    "            i,\n",
    "            nprocs=n_jobs,\n",
    "        )\n",
    "\n",
    "    for which in \"SEAFLOOR_AGE\", \"SPREADING_RATE\":\n",
    "        d_old = os.path.join(output_dir, \"seafloor_age_output\", which)\n",
    "        d_new = os.path.join(output_dir, \"\".join([i.capitalize() for i in which.split(\"_\")]))\n",
    "        os.makedirs(d_new, exist_ok=True)\n",
    "        for t in times:\n",
    "            src = f\"{which}_grid_{t:0.2f}Ma.nc\"\n",
    "            dst = f\"{which.lower()}_{t:0.0f}Ma.nc\"\n",
    "            os.rename(\n",
    "                os.path.join(d_old, src),\n",
    "                os.path.join(d_new, dst)\n",
    "            )\n",
    "        os.rmdir(d_old)\n",
    "    shutil.rmtree(os.path.join(output_dir, \"seafloor_age_output\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86369ab2",
   "metadata": {
    "papermill": {
     "duration": 0.00394,
     "end_time": "2025-07-04T08:09:13.117400",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.113460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sediment thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a701d0e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:13.127290Z",
     "iopub.status.busy": "2025-07-04T08:09:13.127006Z",
     "iopub.status.idle": "2025-07-04T08:09:13.140030Z",
     "shell.execute_reply": "2025-07-04T08:09:13.139328Z"
    },
    "papermill": {
     "duration": 0.020008,
     "end_time": "2025-07-04T08:09:13.141643",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.121635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sedthick_output_dir = os.path.join(output_dir, \"SedimentThickness\")\n",
    "os.makedirs(sedthick_output_dir, exist_ok=True)\n",
    "\n",
    "run_sedthick = overwrite\n",
    "if not run_sedthick:\n",
    "    for time in times:\n",
    "        p = Path(sedthick_output_dir, f\"sediment_thickness_{time:0.0f}Ma.nc\")\n",
    "        if not p.exists():\n",
    "            run_sedthick = True\n",
    "            break\n",
    "\n",
    "if run_sedthick:\n",
    "    # Values taken from predicting-sediment-thickness scripts\n",
    "    initial_grid_spacing = 1.0\n",
    "    final_grid_spacing = 0.1\n",
    "    max_mean_distance = 3000\n",
    "    max_age = 191.87276\n",
    "    mean_age =  61.18406823\n",
    "    mean_distance = 1835.28118479\n",
    "    variance_age = 1934.6999014\n",
    "    variance_distance = 1207521.8995806\n",
    "    age_distance_polynomial_coefficients = [\n",
    "        5.441401190368497,  0.46893096, -0.07320928, -0.24077496, -0.10840657,\n",
    "        0.00381672,  0.06831728,  0.01179914,  0.01158149, -0.39880562,\n",
    "    ]\n",
    "    input_points_initial = generate_input_points_grid_seds(initial_grid_spacing)[0]\n",
    "    input_points_final = generate_input_points_grid_seds(final_grid_spacing)[0]\n",
    "\n",
    "    seafloor_age_filenames = [\n",
    "        (\n",
    "            os.path.join(output_dir, \"SeafloorAge\", f\"seafloor_age_{time:0.0f}Ma.nc\"),\n",
    "            time,\n",
    "        )\n",
    "        for time in times\n",
    "    ]\n",
    "\n",
    "    sedthick_workdir = os.path.join(output_dir, \"sedthick_outputs\")\n",
    "    os.makedirs(sedthick_workdir, exist_ok=True)\n",
    "\n",
    "    if use_provided_plate_model:\n",
    "        sedthick_cobs = [\n",
    "            os.path.join(plate_model_dir, \"North_America_COBs.gpml\"),\n",
    "            os.path.join(\n",
    "                plate_model_dir,\n",
    "                \"StaticGeometries\",\n",
    "                \"AgeGridInput\",\n",
    "                \"Global_EarthByte_GeeK07_COB_Terranes.gpml\",\n",
    "            ),\n",
    "        ]\n",
    "    else:\n",
    "        sedthick_cobs = gplot._continents.filenames\n",
    "\n",
    "    generate_and_write_proximity_data_parallel(\n",
    "        input_points=input_points_initial,\n",
    "        rotation_filenames=gplot.plate_reconstruction.rotation_model.filenames,\n",
    "        proximity_filenames=sedthick_cobs,\n",
    "        proximity_features_are_topological=False,\n",
    "        proximity_feature_types=None,\n",
    "        topological_reconstruction_filenames=gplot.plate_reconstruction.topology_features.filenames,\n",
    "        age_grid_filenames_and_paleo_times=seafloor_age_filenames,\n",
    "        time_increment=1,\n",
    "        output_distance_with_time=True,\n",
    "        output_mean_distance=True,\n",
    "        output_standard_deviation_distance=True,\n",
    "        output_directory=sedthick_workdir,\n",
    "        max_topological_reconstruction_time=None,\n",
    "        continent_obstacle_filenames=gplot._coastlines.filenames,\n",
    "        anchor_plate_id=0,\n",
    "        proximity_distance_threshold_radians=None,\n",
    "        clamp_mean_proximity_distance_radians=max_mean_distance / gplately.EARTH_RADIUS,\n",
    "        output_grd_files=(initial_grid_spacing, final_grid_spacing),\n",
    "        num_cpus=n_jobs,\n",
    "    )\n",
    "\n",
    "    sedthick_output_template = os.path.join(\n",
    "        sedthick_output_dir,\n",
    "        r\"sediment_thickness_{:0.0f}Ma.nc\",\n",
    "    )\n",
    "    age_grid_filename_template = os.path.join(\n",
    "        output_dir,\n",
    "        \"SeafloorAge\",\n",
    "        r\"seafloor_age_{:0.0f}Ma.nc\",\n",
    "    )\n",
    "    distance_grid_filename_template = os.path.join(\n",
    "        sedthick_workdir,\n",
    "        (\n",
    "            f\"mean_distance_{final_grid_spacing:0.1f}d\"\n",
    "            + r\"_{:0.1f}.nc\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    def func(\n",
    "        output_filename,\n",
    "        input_points,\n",
    "        age_grid_filename,\n",
    "        distance_grid_filename,\n",
    "        mean_age,\n",
    "        mean_distance,\n",
    "        variance_age,\n",
    "        variance_distance,\n",
    "        age_distance_polynomial_coefficients,\n",
    "        max_age,\n",
    "        max_distance,\n",
    "        grid_spacing,\n",
    "    ):\n",
    "        result = predict_sedimentation(\n",
    "            input_points=input_points,\n",
    "            age_grid_filename=age_grid_filename,\n",
    "            distance_grid_filename=distance_grid_filename,\n",
    "            mean_age=mean_age,\n",
    "            mean_distance=mean_distance,\n",
    "            variance_age=variance_age,\n",
    "            variance_distance=variance_distance,\n",
    "            age_distance_polynomial_coefficients=age_distance_polynomial_coefficients,\n",
    "            max_age=max_age,\n",
    "            max_distance=max_distance,\n",
    "        )\n",
    "        write_grd_file(\n",
    "            output_filename,\n",
    "            output_data=result,\n",
    "            grid_spacing=grid_spacing,\n",
    "            num_grid_longitudes=None,  # not used\n",
    "            num_grid_latitudes=None,  # not used\n",
    "        )\n",
    "\n",
    "    with joblib.Parallel(n_jobs) as parallel:\n",
    "        parallel(\n",
    "            joblib.delayed(func)(\n",
    "                output_filename=sedthick_output_template.format(time),\n",
    "                input_points=input_points_final,\n",
    "                age_grid_filename=age_grid_filename_template.format(time),\n",
    "                distance_grid_filename=distance_grid_filename_template.format(time),\n",
    "                mean_age=mean_age,\n",
    "                mean_distance=mean_distance,\n",
    "                variance_age=variance_age,\n",
    "                variance_distance=variance_distance,\n",
    "                age_distance_polynomial_coefficients=age_distance_polynomial_coefficients,\n",
    "                max_age=max_age,\n",
    "                max_distance=max_mean_distance,\n",
    "                grid_spacing=final_grid_spacing,\n",
    "            )\n",
    "            for time in times\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2158f3f",
   "metadata": {
    "papermill": {
     "duration": 0.027462,
     "end_time": "2025-07-04T08:09:13.173504",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.146042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Carbonate thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee546bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:13.183266Z",
     "iopub.status.busy": "2025-07-04T08:09:13.182997Z",
     "iopub.status.idle": "2025-07-04T08:09:13.186653Z",
     "shell.execute_reply": "2025-07-04T08:09:13.186096Z"
    },
    "papermill": {
     "duration": 0.010272,
     "end_time": "2025-07-04T08:09:13.188282",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.178010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "carbonate_output_dir = os.path.join(output_dir, \"CarbonateThickness\")\n",
    "os.makedirs(carbonate_output_dir, exist_ok=True)\n",
    "\n",
    "carbonate_workdir = os.path.join(output_dir, \"carbonate_outputs\")\n",
    "os.makedirs(carbonate_workdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902106c4",
   "metadata": {
    "papermill": {
     "duration": 0.025175,
     "end_time": "2025-07-04T08:09:13.217900",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.192725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Paleobathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf27ac5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:13.230876Z",
     "iopub.status.busy": "2025-07-04T08:09:13.230462Z",
     "iopub.status.idle": "2025-07-04T08:09:13.247962Z",
     "shell.execute_reply": "2025-07-04T08:09:13.247282Z"
    },
    "papermill": {
     "duration": 0.026391,
     "end_time": "2025-07-04T08:09:13.249620",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.223229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_paleobath = overwrite\n",
    "if not run_paleobath:\n",
    "    for time in times:\n",
    "        p = Path(carbonate_workdir, f\"paleobathymetry_{time:0.0f}Ma.nc\")\n",
    "        if not p.exists():\n",
    "            run_paleobath = True\n",
    "            break\n",
    "\n",
    "if run_paleobath:\n",
    "    # Basement depth\n",
    "    def func(time, input_dir, output_dir):\n",
    "        agegrid_filename = os.path.join(\n",
    "            input_dir,\n",
    "            f\"seafloor_age_{time:0.0f}Ma.nc\",\n",
    "        )\n",
    "        output_filename = os.path.join(\n",
    "            output_dir,\n",
    "            f\"basement_depth_{time:0.0f}Ma.nc\",\n",
    "        )\n",
    "\n",
    "        agegrid = gplately.Raster(agegrid_filename)\n",
    "        basement_depth = agegrid.copy()\n",
    "        basement_depth.data = convert_age_to_depth(agegrid.data)\n",
    "        basement_depth.save_to_netcdf4(output_filename)\n",
    "\n",
    "\n",
    "    with joblib.Parallel(n_jobs) as parallel:\n",
    "        parallel(\n",
    "            joblib.delayed(func)(\n",
    "                time=time,\n",
    "                input_dir=os.path.join(output_dir, \"SeafloorAge\"),\n",
    "                output_dir=carbonate_workdir,\n",
    "            )\n",
    "            for time in times\n",
    "        )\n",
    "\n",
    "    # Large igneous provinces and seamounts\n",
    "    paleobath_data_dir = os.path.join(\n",
    "        \"submodules\",\n",
    "        \"paleobathymetry-workflow\",\n",
    "        \"InputData\",\n",
    "    )\n",
    "    gdf_seamounts = gpd.read_file(\n",
    "        os.path.join(\n",
    "            paleobath_data_dir,\n",
    "            \"Seamount_shapefile\",\n",
    "            \"Johansson_etal_2018_VolcanicProvinces_v2_NW-edit.shp\",\n",
    "        )\n",
    "    )\n",
    "    gdf_LIPs = gpd.read_file(\n",
    "        os.path.join(\n",
    "            paleobath_data_dir,\n",
    "            \"LIP_shapefile\",\n",
    "            \"LIPs_merged.shp\",\n",
    "        )\n",
    "    )\n",
    "    gdf_features = gpd.pd.concat([gdf_LIPs, gdf_seamounts])\n",
    "\n",
    "    basement_depth = rioxarray.open_rasterio(\n",
    "        os.path.join(carbonate_workdir, \"basement_depth_0Ma.nc\"),\n",
    "        masked=True,\n",
    "    )\n",
    "    basement_depth = basement_depth.sel(band=1)\n",
    "    basement_depth = basement_depth.drop(['band', 'spatial_ref'])\n",
    "    basement_depth.rio.write_crs(\"epsg:4326\", inplace=True)  # set crs\n",
    "\n",
    "    os.makedirs(os.path.join(carbonate_workdir, \"GDH1\"), exist_ok=True)\n",
    "\n",
    "    # LIPs\n",
    "    calculate_depth_contours(\n",
    "        basement_depth,\n",
    "        gdf_features,\n",
    "        contour_interval=50,\n",
    "        LIP_depth_rounding=50,\n",
    "        LIP_output_dir=carbonate_workdir,\n",
    "        clip_contour_to_outline=\"yes\",\n",
    "        LIP_model_name=\"GDH1\",\n",
    "        path_contoured_LIPs=carbonate_workdir,\n",
    "        feature_type=\"LIPs_seamounts\",\n",
    "        gdf_LIP_large=None,\n",
    "    )\n",
    "\n",
    "    # Conjugate LIPs\n",
    "    create_lip_conjugates(\n",
    "        LIP_contour_poly=os.path.join(\n",
    "            carbonate_workdir,\n",
    "            \"contoured_LIPs_seamounts_0Ma.shp\",\n",
    "        ),\n",
    "        rotation_model=plate_model.rotation_model.filenames,\n",
    "        topology_features=plate_model.topology_features.filenames,\n",
    "        LIP_conjugate_outdir=carbonate_workdir,\n",
    "    )\n",
    "\n",
    "    path_rotated_polygons = os.path.join(\n",
    "        carbonate_workdir,\n",
    "        \"GDH1\",\n",
    "        \"rotated_polygons\",\n",
    "    )\n",
    "    os.makedirs(path_rotated_polygons, exist_ok=True)\n",
    "    # Working on 0 Ma ONLY.\n",
    "    # This is because we need to create swell_stats.txt (which is only created at 0 Ma)\n",
    "    rotation_LIP_shapefile_and_buffer(\n",
    "        time=0.0,\n",
    "        path_0_shp=os.path.join(carbonate_workdir, \"contoured_LIPs_seamounts_0Ma.shp\"),\n",
    "        rotation_filenames=plate_model.rotation_model.filenames,\n",
    "        path_rotated_polygons=path_rotated_polygons,\n",
    "        feature_type=\"LIPs_seamounts\",\n",
    "        include_conjugate_LIPs=\"yes\",\n",
    "        LIP_output_dir=carbonate_workdir,\n",
    "        LIP_model_name=\"GDH1\",\n",
    "        cooling_model=\"GDH1\",\n",
    "        large_LIP_path=None,\n",
    "        buffer_radius_deg=1.0,\n",
    "        RHCW_age_depth_interp=None,\n",
    "    )\n",
    "\n",
    "    with joblib.Parallel(n_jobs) as parallel:\n",
    "        parallel(\n",
    "            joblib.delayed(rotation_LIP_shapefile_and_buffer)(\n",
    "                time=time,\n",
    "                path_0_shp=os.path.join(carbonate_workdir, \"contoured_LIPs_seamounts_0Ma.shp\"),\n",
    "                rotation_filenames=plate_model.rotation_model.filenames,\n",
    "                path_rotated_polygons=path_rotated_polygons,\n",
    "                feature_type=\"LIPs_seamounts\",\n",
    "                include_conjugate_LIPs=\"yes\",\n",
    "                LIP_output_dir=carbonate_workdir,\n",
    "                LIP_model_name=\"GDH1\",\n",
    "                cooling_model=\"GDH1\",\n",
    "                large_LIP_path=None,\n",
    "                buffer_radius_deg=1.0,\n",
    "                RHCW_age_depth_interp=None,\n",
    "            )\n",
    "            for time in times\n",
    "        )\n",
    "        parallel(\n",
    "            joblib.delayed(mp_wrapper_for_shapefile_to_raster)(\n",
    "                time=time,\n",
    "                path_rotated_polygons=path_rotated_polygons,\n",
    "                feature_type=\"LIPs_seamounts\",\n",
    "                cooling_model=\"GDH1\",\n",
    "                grid_spacing=0.1,\n",
    "                lon_min=-180,\n",
    "                lon_max=180,\n",
    "                lat_min=-90,\n",
    "                lat_max=90,\n",
    "                path_output_grids=carbonate_workdir,\n",
    "            )\n",
    "            for time in times\n",
    "        )\n",
    "\n",
    "        # Create combined paleobathymetry\n",
    "        parallel(\n",
    "            joblib.delayed(calculate_paleobathymetry)(\n",
    "                sedthick_filename=os.path.join(\n",
    "                    output_dir,\n",
    "                    \"SedimentThickness\",\n",
    "                    f\"sediment_thickness_{time:0.0f}Ma.nc\",\n",
    "                ),\n",
    "                basement_depth_filename=os.path.join(\n",
    "                    carbonate_workdir,\n",
    "                    f\"basement_depth_{time:0.0f}Ma.nc\",\n",
    "                ),\n",
    "                lip_height_filename=os.path.join(\n",
    "                    carbonate_workdir,\n",
    "                    f\"reconstructed_LIPs_seamounts_{time:0.0f}Ma.nc\",\n",
    "                ),\n",
    "                output_filename=os.path.join(\n",
    "                    carbonate_workdir,\n",
    "                    f\"paleobathymetry_{time:0.0f}Ma.nc\",\n",
    "                ),\n",
    "            )\n",
    "            for time in times\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732aa2dc",
   "metadata": {
    "papermill": {
     "duration": 0.004883,
     "end_time": "2025-07-04T08:09:13.259294",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.254411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Carbonate thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bebdde14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:13.270158Z",
     "iopub.status.busy": "2025-07-04T08:09:13.269635Z",
     "iopub.status.idle": "2025-07-04T08:09:13.283215Z",
     "shell.execute_reply": "2025-07-04T08:09:13.282570Z"
    },
    "papermill": {
     "duration": 0.020534,
     "end_time": "2025-07-04T08:09:13.284663",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.264129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_carbonate = overwrite\n",
    "if not run_carbonate:\n",
    "    for time in times:\n",
    "        p = Path(carbonate_output_dir, f\"carbonate_thickness_{time:0.0f}Ma.nc\")\n",
    "        if not p.exists():\n",
    "            run_carbonate = True\n",
    "            break\n",
    "\n",
    "if run_carbonate:\n",
    "    ccd_curve_filename = os.path.join(\n",
    "        carbonate_path,\n",
    "        \"input_data\",\n",
    "        \"Boss_Wilkinson_1991_global_CCD.txt\",\n",
    "    )\n",
    "    max_carbonate_decomp_sed_rate_cm_per_ky_curve_filename = os.path.join(\n",
    "        carbonate_path,\n",
    "        \"input_data\",\n",
    "        \"sed_rate_v6.txt\",\n",
    "    )\n",
    "\n",
    "    # Create symlinks for seafloor age and bathymetry files\n",
    "    # (necessary for carbonate thickness function)\n",
    "    for time in times:\n",
    "        # Seafloor age\n",
    "        link_path = Path(\n",
    "            output_dir,\n",
    "            \"SeafloorAge\",\n",
    "            f\"seafloor_age_{time:0.0f}.nc\",\n",
    "        )\n",
    "        target_path = Path(\n",
    "            output_dir,\n",
    "            \"SeafloorAge\",\n",
    "            f\"seafloor_age_{time:0.0f}Ma.nc\",\n",
    "        )\n",
    "        if link_path.exists():\n",
    "            link_path.unlink()\n",
    "        link_path.symlink_to(target_path.relative_to(link_path.parent))\n",
    "\n",
    "        # Bathymetry\n",
    "        link_path = Path(\n",
    "            carbonate_workdir,\n",
    "            f\"paleobathymetry_{time:0.0f}.nc\",\n",
    "        )\n",
    "        target_path = Path(\n",
    "            carbonate_workdir,\n",
    "            f\"paleobathymetry_{time:0.0f}Ma.nc\",\n",
    "        )\n",
    "        if link_path.exists():\n",
    "            link_path.unlink()\n",
    "        link_path.symlink_to(target_path.relative_to(link_path.parent))\n",
    "\n",
    "    grid_spacing = 0.5\n",
    "    latitude_range = (-90, 90)\n",
    "    longitude_range = (-180, 180)\n",
    "    input_points = generate_input_points_grid_carb(\n",
    "        grid_spacing_degrees=grid_spacing,\n",
    "        latitude_range=latitude_range,\n",
    "        longitude_range=longitude_range,\n",
    "    )\n",
    "    age_grid_filename_components = (\n",
    "        os.path.join(output_dir, \"SeafloorAge\", \"seafloor_age_\"),  # prefix\n",
    "        0,  # decimal places in time component\n",
    "        \"nc\",  # file extension\n",
    "    )\n",
    "    bathymetry_filename_components = (\n",
    "        os.path.join(carbonate_workdir, \"paleobathymetry_\"),  # prefix\n",
    "        0,  # decimal places in time component\n",
    "        \"nc\",  # file extension\n",
    "    )\n",
    "\n",
    "\n",
    "    def func(output_dir, grid_spacing, latitude_range, longitude_range, **kwargs):\n",
    "        kwargs[\"rotation_model\"] = pygplates.RotationModel(kwargs[\"rotation_model\"])\n",
    "        sediment_thickness_data = calc_sedimentation(**kwargs)\n",
    "        (carbonate_decompacted_sediment_thickness_data,\n",
    "        carbonate_compacted_sediment_thickness_data,\n",
    "        carbonate_deposition_mask_data) = sediment_thickness_data\n",
    "        time = kwargs.get(\"time\")\n",
    "        output_prefix = os.path.join(\n",
    "            output_dir,\n",
    "            f\"carbonate_thickness_{time:0.0f}Ma\",\n",
    "        )\n",
    "        write_data(\n",
    "            data=carbonate_decompacted_sediment_thickness_data,\n",
    "            output_filename_prefix=output_prefix,\n",
    "            grid_spacing=grid_spacing,\n",
    "            latitude_range=latitude_range,\n",
    "            longitude_range=longitude_range,\n",
    "        )\n",
    "\n",
    "\n",
    "    with joblib.Parallel(n_jobs) as parallel:\n",
    "        parallel(\n",
    "            joblib.delayed(func)(\n",
    "                output_dir=carbonate_output_dir,\n",
    "                grid_spacing=grid_spacing,\n",
    "                latitude_range=latitude_range,\n",
    "                longitude_range=longitude_range,\n",
    "                input_points=input_points,\n",
    "                age_grid_filename_components=age_grid_filename_components,\n",
    "                bathymetry_filename_components=bathymetry_filename_components,\n",
    "                bathymetry_filename_oldest_time=max(times),\n",
    "                topology_filenames=plate_model.topology_features.filenames,\n",
    "                rotation_model=plate_model.rotation_model.filenames,\n",
    "                ccd_curve_filename=ccd_curve_filename,\n",
    "                max_carbonate_decomp_sed_rate_cm_per_ky_curve_filename=max_carbonate_decomp_sed_rate_cm_per_ky_curve_filename,\n",
    "                carbonate_anchor_plate_id=0,\n",
    "                time=time,\n",
    "            )\n",
    "            for time in times\n",
    "        )\n",
    "\n",
    "    # Clean up .xy files and symlinks for seafloor age and bathymetry files\n",
    "    for time in times:\n",
    "        # .xy carbonate thickness files\n",
    "        xy_path = Path(\n",
    "            carbonate_output_dir,\n",
    "            f\"carbonate_thickness_{time:0.0f}Ma.xy\",\n",
    "        )\n",
    "        if xy_path.exists():\n",
    "            xy_path.unlink()\n",
    "\n",
    "        # Seafloor age\n",
    "        link_path = Path(\n",
    "            output_dir,\n",
    "            \"SeafloorAge\",\n",
    "            f\"seafloor_age_{time:0.0f}.nc\",\n",
    "        )\n",
    "        if link_path.exists() and link_path.is_symlink():\n",
    "            link_path.unlink()\n",
    "\n",
    "        # Bathymetry\n",
    "        link_path = Path(\n",
    "            carbonate_workdir,\n",
    "            f\"paleobathymetry_{time:0.0f}.nc\",\n",
    "        )\n",
    "        if link_path.exists() and link_path.is_symlink():\n",
    "            link_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be88d2e",
   "metadata": {
    "papermill": {
     "duration": 0.003952,
     "end_time": "2025-07-04T08:09:13.292533",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.288581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Crustal thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c048d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:13.301082Z",
     "iopub.status.busy": "2025-07-04T08:09:13.300828Z",
     "iopub.status.idle": "2025-07-04T08:09:13.307723Z",
     "shell.execute_reply": "2025-07-04T08:09:13.307303Z"
    },
    "papermill": {
     "duration": 0.012592,
     "end_time": "2025-07-04T08:09:13.308949",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.296357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "crust_output_dir = Path(\n",
    "    output_dir,\n",
    "    \"CrustalThickness\",\n",
    ")\n",
    "crust_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_crust = overwrite\n",
    "if not run_crust:\n",
    "    for time in times:\n",
    "        p = Path(crust_output_dir, f\"crustal_thickness_{time:0.0f}Ma.nc\")\n",
    "        if not p.exists():\n",
    "            run_crust = True\n",
    "            break\n",
    "\n",
    "crust_workdir = Path(\n",
    "    output_dir,\n",
    "    \"crust_outputs\",\n",
    ")\n",
    "if run_crust:\n",
    "    crust_workdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed929405",
   "metadata": {
    "papermill": {
     "duration": 0.003824,
     "end_time": "2025-07-04T08:09:13.316580",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.312756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Paleotopography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a33b4c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:13.324839Z",
     "iopub.status.busy": "2025-07-04T08:09:13.324599Z",
     "iopub.status.idle": "2025-07-04T08:09:13.331840Z",
     "shell.execute_reply": "2025-07-04T08:09:13.331148Z"
    },
    "papermill": {
     "duration": 0.013251,
     "end_time": "2025-07-04T08:09:13.333621",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.320370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "area_threshold = 0.0\n",
    "subdivision_depth = 2\n",
    "resolution = 0.5  # degrees\n",
    "ocean_elevation = -1000.0\n",
    "shallow_elevation = -200.0\n",
    "land_elevation = 200.0\n",
    "mountain_relief = 3100.0\n",
    "mountain_buffer_distance = 2.0  # degrees\n",
    "\n",
    "run_paleotopo = overwrite\n",
    "if not run_paleotopo:\n",
    "    for time in times:\n",
    "        p = Path(crust_workdir, f\"paleotopo_{resolution:0.2f}d_{time:0.2f}Ma.nc\")\n",
    "        if not p.exists():\n",
    "            run_paleotopo = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c4130ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:13.342484Z",
     "iopub.status.busy": "2025-07-04T08:09:13.342227Z",
     "iopub.status.idle": "2025-07-04T08:09:17.417021Z",
     "shell.execute_reply": "2025-07-04T08:09:17.416158Z"
    },
    "papermill": {
     "duration": 4.081381,
     "end_time": "2025-07-04T08:09:17.419003",
     "exception": false,
     "start_time": "2025-07-04T08:09:13.337622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paleotopo_basename = \"paleotopography-data\"\n",
    "paleotopo_dir = Path(crust_workdir, paleotopo_basename)\n",
    "paleotopo_filename = Path(crust_workdir, paleotopo_basename + \".tgz\")\n",
    "paleotopo_url = \"https://www.earthbyte.org/webdav/ftp/earthbyte/Paleotopography/paleotopography-data.tgz\"\n",
    "cookie_cut_dir = Path(crust_workdir, \"cookie_cut\")\n",
    "\n",
    "if run_paleotopo:\n",
    "    # Download paleotopography polygons\n",
    "    if not paleotopo_filename.exists():\n",
    "        with requests.get(paleotopo_url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with paleotopo_filename.open(\"wb\") as f:\n",
    "                for chunk in tqdm(r.iter_content(chunk_size=1024000)):\n",
    "                    f.write(chunk)\n",
    "    # Extract archive\n",
    "    shutil.unpack_archive(paleotopo_filename, extract_dir=paleotopo_dir)\n",
    "\n",
    "    # Load polygons\n",
    "    polygons_dir = Path(\n",
    "        paleotopo_dir,\n",
    "        \"Paleogeography_Matthews2016_410-2Ma_Shapefiles\",\n",
    "    )\n",
    "    gdf_paleotopo = []\n",
    "    for d in polygons_dir.iterdir():\n",
    "        if not d.is_dir():\n",
    "            continue\n",
    "        for fname in d.iterdir():\n",
    "            if not fname.name.endswith(\".shp\"):\n",
    "                continue\n",
    "            which = fname.name.split(\"_\")[0]\n",
    "            gdf = gpd.read_file(fname)\n",
    "            gdf[\"NAME\"] = which\n",
    "            gdf[\"ENV\"] = which\n",
    "            gdf_paleotopo.append(gdf)\n",
    "    gdf_paleotopo = pd.concat(gdf_paleotopo, ignore_index=True).dropna(axis=\"columns\")\n",
    "    # gdf_paleotopo = gdf_paleotopo.drop(columns=\"PLATEID1\").explode()\n",
    "\n",
    "    # Cookie-cut polygons for plate model\n",
    "    cookie_cut_dir.mkdir(exist_ok=True)\n",
    "    sp_file = Path(crust_workdir, \"static_polygons.shp\")\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        pygplates.reconstruct(\n",
    "            plate_model.static_polygons,\n",
    "            plate_model.rotation_model,\n",
    "            str(sp_file),\n",
    "            0.0,\n",
    "        )\n",
    "    gdf_sp = gpd.read_file(sp_file).explode()\n",
    "    gdf_sp = gdf_sp[gdf_sp.geometry.type == \"Polygon\"]\n",
    "    gdf_sp = gdf_sp[[\"PLATEID1\", gdf_sp.geometry.name]]\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        gdf_paleotopo = gpd.overlay(\n",
    "            gdf_paleotopo,\n",
    "            gdf_sp,\n",
    "            how=\"intersection\",\n",
    "        )\n",
    "    inds = np.squeeze(np.where(\n",
    "        (gdf_paleotopo[\"PLATEID1_2\"].str.startswith(\"5\"))\n",
    "        | (gdf_paleotopo[\"PLATEID1_1\"] == 616)\n",
    "    ))\n",
    "    for ind in inds:\n",
    "        gdf_paleotopo.at[ind, \"PLATEID1_2\"] = gdf_paleotopo.at[ind, \"PLATEID1_1\"]\n",
    "    gdf_paleotopo = gdf_paleotopo.rename(\n",
    "        columns={\"PLATEID1_2\": \"PLATEID1\"}\n",
    "    ).drop(columns=\"PLATEID1_1\")\n",
    "\n",
    "    # gdf_paleotopo = gpd.overlay(\n",
    "    #     gdf_paleotopo,\n",
    "    #     gdf_sp,\n",
    "    #     how=\"intersection\",\n",
    "    #     keep_geom_type=True,\n",
    "    # )\n",
    "    for which in (\"i\", \"sm\", \"m\", \"lm\"):\n",
    "        p = Path(cookie_cut_dir, f\"{which}_402_2.shp\")\n",
    "        gdf_which = gdf_paleotopo[gdf_paleotopo[\"ENV\"] == which]\n",
    "        gdf_which.to_file(str(p))\n",
    "else:\n",
    "    gdf_paleotopo = []\n",
    "    for which in (\"i\", \"sm\", \"m\", \"lm\"):\n",
    "        p = Path(cookie_cut_dir, f\"{which}_402_2.shp\")\n",
    "        gdf_paleotopo.append(gpd.read_file(p))\n",
    "    gdf_paleotopo = pd.concat(gdf_paleotopo, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61261416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:17.430625Z",
     "iopub.status.busy": "2025-07-04T08:09:17.430135Z",
     "iopub.status.idle": "2025-07-04T08:09:17.434754Z",
     "shell.execute_reply": "2025-07-04T08:09:17.434080Z"
    },
    "papermill": {
     "duration": 0.012029,
     "end_time": "2025-07-04T08:09:17.436431",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.424402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tween_dir = str(Path(crust_workdir, \"tween_dir\"))\n",
    "Path(tween_dir).mkdir(exist_ok=True)\n",
    "topography_filename = str(Path(paleotopo_dir, \"topo15_3600x1800.nc\"))\n",
    "classes_filename = str(Path(crust_workdir, \"present_day_topo_as_classes.nc\"))\n",
    "presentday_filename = str(Path(crust_workdir, \"present_day_paleogeography.gmt\"))\n",
    "\n",
    "if run_paleotopo:\n",
    "    create_present_day_features(\n",
    "        topography_filename=topography_filename,\n",
    "        classes_filename=classes_filename,\n",
    "        features_filename=presentday_filename,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3b1c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:17.446587Z",
     "iopub.status.busy": "2025-07-04T08:09:17.446288Z",
     "iopub.status.idle": "2025-07-04T08:09:17.454785Z",
     "shell.execute_reply": "2025-07-04T08:09:17.454032Z"
    },
    "papermill": {
     "duration": 0.015315,
     "end_time": "2025-07-04T08:09:17.456314",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.440999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Takes an hour or two, so only run if necessary\n",
    "tween_times = sorted(gdf_paleotopo[\"TIME\"].unique())\n",
    "\n",
    "run_tween = overwrite\n",
    "if not run_tween:\n",
    "    for t1, t2 in zip(tween_times[:-1], tween_times[1:]):\n",
    "        for which in (\n",
    "            \"tweentest_land\",\n",
    "            \"tweentest_ocean\",\n",
    "            \"mountain_regression\",\n",
    "            \"mountain_stable\",\n",
    "            \"mountain_transgression\",\n",
    "        ):\n",
    "            p = Path(tween_dir, f\"{which}_{t1:0.2f}Ma_{t2:0.2f}Ma.gpmlz\")\n",
    "            if not p.exists():\n",
    "                run_tween = True\n",
    "                break\n",
    "\n",
    "if run_tween:\n",
    "    tween_paleoshorelines_inplace(\n",
    "        tween_dir=tween_dir,\n",
    "        basedir=str(cookie_cut_dir),\n",
    "        rotation_filenames=plate_model.rotation_model.filenames,\n",
    "        presentday_filename=presentday_filename,\n",
    "        times=tween_times,\n",
    "        resolution=resolution,\n",
    "        nprocs=n_jobs,\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9732932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:17.466686Z",
     "iopub.status.busy": "2025-07-04T08:09:17.466398Z",
     "iopub.status.idle": "2025-07-04T08:09:17.471540Z",
     "shell.execute_reply": "2025-07-04T08:09:17.470964Z"
    },
    "papermill": {
     "duration": 0.012081,
     "end_time": "2025-07-04T08:09:17.472983",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.460902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create paleotopography grids\n",
    "if run_paleotopo:\n",
    "    paleogeography_timeslice_list = sorted(gdf_paleotopo[\"TIME\"].unique())\n",
    "    paleogeography_timeslice_list.append(0.0)\n",
    "    paleogeography_timeslice_list = np.array(paleogeography_timeslice_list)\n",
    "    paleogeography_timeslice_list.sort()\n",
    "\n",
    "    with joblib.Parallel(n_jobs) as parallel:\n",
    "        parallel(\n",
    "            joblib.delayed(paleotopography_job)(\n",
    "                reconstruction_time=time,\n",
    "                paleogeography_timeslice_list=paleogeography_timeslice_list,\n",
    "                tween_basedir=tween_dir,\n",
    "                reconstruction_basedir=str(Path(crust_workdir, \"cookie_cut\")),\n",
    "                output_dir=crust_workdir,\n",
    "                file_format=\"gpmlz\",\n",
    "                rotation_file=plate_model.rotation_model.filenames,\n",
    "                COBterrane_file=gplot._continents.filenames,\n",
    "                agegrid_file_template=\"\",\n",
    "                lowland_elevation=land_elevation,\n",
    "                shallow_marine_elevation=shallow_elevation,\n",
    "                max_mountain_elevation=mountain_relief,\n",
    "                depth_for_unknown_ocean=ocean_elevation,\n",
    "                sampling=resolution,\n",
    "                mountain_buffer_distance_degrees=mountain_buffer_distance,\n",
    "                area_threshold=area_threshold,\n",
    "                grid_smoothing_wavelength_kms=None,\n",
    "                merge_with_bathymetry=False,\n",
    "                land_or_ocean_precedence='land',\n",
    "                netcdf3_output=False,\n",
    "                subdivision_depth=subdivision_depth,\n",
    "                present_day_filename=presentday_filename,\n",
    "            )\n",
    "            for time in times\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be2c03",
   "metadata": {
    "papermill": {
     "duration": 0.004041,
     "end_time": "2025-07-04T08:09:17.480943",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.476902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Crustal thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f976f769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:17.490288Z",
     "iopub.status.busy": "2025-07-04T08:09:17.490043Z",
     "iopub.status.idle": "2025-07-04T08:09:17.493519Z",
     "shell.execute_reply": "2025-07-04T08:09:17.492906Z"
    },
    "papermill": {
     "duration": 0.009657,
     "end_time": "2025-07-04T08:09:17.494803",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.485146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if run_crust:\n",
    "    with joblib.Parallel(n_jobs) as parallel:\n",
    "        parallel(\n",
    "            joblib.delayed(calculate_crustal_thickness)(\n",
    "                time=time,\n",
    "                input_dir=str(crust_workdir),\n",
    "                output_dir=str(crust_output_dir),\n",
    "            )\n",
    "            for time in times\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000c958",
   "metadata": {
    "papermill": {
     "duration": 0.003822,
     "end_time": "2025-07-04T08:09:17.502474",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.498652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Oceanic crustal $\\mathrm{CO_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ceb6f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:17.511151Z",
     "iopub.status.busy": "2025-07-04T08:09:17.510893Z",
     "iopub.status.idle": "2025-07-04T08:09:17.518071Z",
     "shell.execute_reply": "2025-07-04T08:09:17.517557Z"
    },
    "papermill": {
     "duration": 0.013347,
     "end_time": "2025-07-04T08:09:17.519539",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.506192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "co2_output_dir = Path(\n",
    "    output_dir,\n",
    "    \"CrustalCO2\",\n",
    ")\n",
    "co2_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_co2 = overwrite\n",
    "if not run_co2:\n",
    "    for time in times:\n",
    "        p = Path(co2_output_dir, f\"crustal_co2_{time:0.0f}Ma.nc\")\n",
    "        if not p.exists():\n",
    "            run_co2 = True\n",
    "            break\n",
    "\n",
    "if run_co2:\n",
    "    calculate_crustal_co2(\n",
    "        times=times,\n",
    "        seafloor_age_dir=seafloor_age_output_dir,\n",
    "        output_dir=co2_output_dir,\n",
    "        n_jobs=n_jobs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b521a",
   "metadata": {
    "papermill": {
     "duration": 0.00399,
     "end_time": "2025-07-04T08:09:17.527604",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.523614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5594376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:17.539999Z",
     "iopub.status.busy": "2025-07-04T08:09:17.539663Z",
     "iopub.status.idle": "2025-07-04T08:09:17.545798Z",
     "shell.execute_reply": "2025-07-04T08:09:17.545088Z"
    },
    "papermill": {
     "duration": 0.014826,
     "end_time": "2025-07-04T08:09:17.547375",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.532549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "erodep_output_dir = Path(output_dir, \"ErosionDeposition\")\n",
    "erodep_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "run_erodep = False\n",
    "erodep_times = range(0, 270, 5)\n",
    "for time in erodep_times:\n",
    "    if time <= min_time - 5 or time >= max_time + 5:\n",
    "        continue\n",
    "    p = Path(erodep_output_dir, f\"erosion_deposition_{time:0.0f}Ma.nc\")\n",
    "    if not p.exists():\n",
    "        run_erodep = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c08072b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:17.557824Z",
     "iopub.status.busy": "2025-07-04T08:09:17.557559Z",
     "iopub.status.idle": "2025-07-04T08:09:17.562227Z",
     "shell.execute_reply": "2025-07-04T08:09:17.561703Z"
    },
    "papermill": {
     "duration": 0.011489,
     "end_time": "2025-07-04T08:09:17.563604",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.552115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if run_erodep:\n",
    "    erodep_workdir = Path(output_dir, \"erodep_outputs\")\n",
    "    erodep_workdir.mkdir(exist_ok=True)\n",
    "\n",
    "    erodep_url = \"https://zenodo.org/records/14010839/files/erosion_deposition_files.zip?download=1\"\n",
    "    erodep_filename = Path(erodep_workdir, \"erosion_deposition_files.zip\")\n",
    "    if not erodep_filename.exists():\n",
    "        # Download archive from Zenodo\n",
    "        with requests.get(erodep_url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with erodep_filename.open(\"wb\") as f:\n",
    "                for chunk in tqdm(r.iter_content(chunk_size=1024000)):\n",
    "                    f.write(chunk)\n",
    "    # Extract archive\n",
    "    shutil.unpack_archive(erodep_filename, extract_dir=erodep_workdir)\n",
    "\n",
    "    # Copy missing files\n",
    "    srcdir = Path(erodep_workdir, \"erosion_deposition_files\")\n",
    "    for time in erodep_times:\n",
    "        if time <= min_time - 5 or time >= max_time + 5:\n",
    "            continue\n",
    "        src = Path(srcdir, f\"erodep{time:0.0f}Ma.nc\")\n",
    "        dst = Path(erodep_output_dir, f\"erosion_deposition_{time:0.0f}Ma.nc\")\n",
    "        if dst.exists():\n",
    "            continue\n",
    "        shutil.copy2(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070021a1",
   "metadata": {
    "papermill": {
     "duration": 0.003922,
     "end_time": "2025-07-04T08:09:17.571445",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.567523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove all working directories to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "827bef4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:09:17.580067Z",
     "iopub.status.busy": "2025-07-04T08:09:17.579806Z",
     "iopub.status.idle": "2025-07-04T08:09:17.582951Z",
     "shell.execute_reply": "2025-07-04T08:09:17.582421Z"
    },
    "papermill": {
     "duration": 0.009041,
     "end_time": "2025-07-04T08:09:17.584275",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.575234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cleanup:\n",
    "    for d in (\n",
    "        \"carbonate_outputs\",\n",
    "        \"crust_outputs\",\n",
    "        \"erodep_outputs\",\n",
    "        \"sedthick_outputs\",\n",
    "    ):\n",
    "        p = Path(output_dir, d)\n",
    "        if p.exists():\n",
    "            shutil.rmtree(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3aaa7f",
   "metadata": {
    "papermill": {
     "duration": 0.00433,
     "end_time": "2025-07-04T08:09:17.592761",
     "exception": false,
     "start_time": "2025-07-04T08:09:17.588431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prospectivity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.335544,
   "end_time": "2025-07-04T08:09:18.921834",
   "environment_variables": {},
   "exception": null,
   "input_path": "00a-generate_data.ipynb",
   "output_path": "00a-generate_data_output.ipynb",
   "parameters": {},
   "start_time": "2025-07-04T08:08:52.586290",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}